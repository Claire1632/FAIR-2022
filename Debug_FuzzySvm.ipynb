{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data import Vertebral_column\n",
    "from data import Co_Author\n",
    "from Processing_Data import Abanole\n",
    "from Processing_Data import Ecoli\n",
    "from Processing_Data import Ecloli1\n",
    "from Processing_Data import Ecoli3\n",
    "from Processing_Data import Glass1\n",
    "from Processing_Data import Glass4\n",
    "from Processing_Data import Haberman\n",
    "from Processing_Data import Waveform\n",
    "from Processing_Data import New_thyroid2\n",
    "from Processing_Data import Page_blocks\n",
    "from Processing_Data import Pima_Indians_Diabetes\n",
    "from Processing_Data import Satimage\n",
    "from Processing_Data import Transfusion\n",
    "from Processing_Data import Yeast\n",
    "from data import indian_liver_patient\n",
    "#from data import spect_heart\n",
    "from wsvm.application import Wsvm\n",
    "from svm.application import Svm\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.metrics import f1_score\n",
    "from sklearn.metrics  import classification_report,precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from datetime import datetime\n",
    "from fuzzy.weight import fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(X, y,name_method =\"own_class_center_divided\", name_function = \"lin_center_own\", beta = None,C = None, gamma = None, u = None, sigma = None):\n",
    "    method = fuzzy.method()\n",
    "    function = fuzzy.function()\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    try:\n",
    "        if name_method == \"own_class_center\": \n",
    "            d = method.own_class_center(X, y)\n",
    "        elif name_method == \"estimated_hyper_lin\": # actual_hyper_lin, own_class_center\n",
    "            d = method.estimated_hyper_lin(X, y)\n",
    "        elif name_method == \"own_class_center_opposite\":\n",
    "            d = method.own_class_center_opposite(X, y)\n",
    "        elif name_method == 'actual_hyper_lin':\n",
    "            d = method.actual_hyper_lin(X, y,C = C, gamma = gamma)\n",
    "        elif name_method == 'own_class_center_divided':\n",
    "            print(\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\")\n",
    "            d = method.own_class_center_divided(X, y)\n",
    "        else:\n",
    "            print('dont exist method')\n",
    "        \n",
    "        if name_function == \"lin\":\n",
    "            W = function.lin(d)\n",
    "        elif name_function == \"exp\":\n",
    "            W = function.exp(d, beta)\n",
    "        elif name_function == \"lin_center_own\":\n",
    "            W = function.lin_center_own(d, pos_index,neg_index)\n",
    "        elif name_function == 'gau':\n",
    "            W = function.gau(d, u, sigma)\n",
    "    except Exception as e:\n",
    "        print('dont exist function')\n",
    "        print(e)\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    r_pos = 1\n",
    "    r_neg = len(pos_index)/len(neg_index)\n",
    "    m = []\n",
    "    W = np.array(W)\n",
    "    m = W[pos_index]*r_pos\n",
    "    m = np.append(m, W[neg_index]*r_neg)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsvm(C,X_train, y_train,X_test,distribution_weight=None):\n",
    "    model = Wsvm(C,distribution_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gmean(y_test,y_pred):\n",
    "    cm_WSVM = metrics.confusion_matrix(y_test, y_pred)\n",
    "    sensitivity = cm_WSVM[1,1]/(cm_WSVM[1,0]+cm_WSVM[1,1])\n",
    "    specificity = cm_WSVM[0,0]/(cm_WSVM[0,0]+cm_WSVM[0,1])\n",
    "    gmean = math.sqrt(sensitivity*specificity)\n",
    "    return sensitivity,specificity,gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tomek(X,y, class_type):\n",
    "    nn = NearestNeighbors(n_neighbors=2)\n",
    "    nn.fit(X)\n",
    "    nn_index = nn.kneighbors(X, return_distance=False)[:, 1]\n",
    "    links = np.zeros(len(y), dtype=bool)\n",
    "    # find which class to not consider\n",
    "    class_excluded = [c for c in np.unique(y) if c not in class_type]\n",
    "    X_dangxet = []\n",
    "    X_tl = []\n",
    "    # there is a Tomek link between two samples if they are both nearest\n",
    "    # neighbors of each others.\n",
    "    for index_sample, target_sample in enumerate(y):\n",
    "        if target_sample in class_excluded:\n",
    "            continue\n",
    "        if y[nn_index[index_sample]] != target_sample:\n",
    "            if nn_index[nn_index[index_sample]] == index_sample:\n",
    "                X_tl.append(index_sample)\n",
    "                X_dangxet.append(nn_index[index_sample])\n",
    "                links[index_sample] = True\n",
    "\n",
    "    return links,X_dangxet,X_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tomelinks(C,X_train_val,y_train_val,X_test_val, y_test_val,n_neighbors,clf=None,namemethod=None,namefunction=None):\n",
    "    links,xdx,xtl = is_tomek(X_train_val,y_train_val,class_type=[-1.0])\n",
    "    if clf == None:\n",
    "        if namemethod == None:\n",
    "            distribution_weight = compute_weight(X_train_val, y_train_val)\n",
    "            print(\"\\nW mac dinh\\n\")\n",
    "        else:\n",
    "            if namefunction == \"exp\":\n",
    "                distribution_weight = compute_weight(X_train_val, y_train_val,name_method = namemethod,name_function = namefunction,beta = 0.5)\n",
    "                print(\"BETA: \",0.5)\n",
    "            else:\n",
    "                distribution_weight = compute_weight(X_train_val, y_train_val,name_method = namemethod,name_function = namefunction)\n",
    "                print(\"Ko exp\")\n",
    "                #print(distribution_weight)\n",
    "        clf = Wsvm(C,distribution_weight)\n",
    "        print(clf)\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "    else:\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "    y_predict = clf.predict(X_test_val)\n",
    "    sensitivity,specificity,gmean = Gmean(y_test_val,y_predict)\n",
    "    nn2 = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn2.fit(X_train_val)\n",
    "    y_nn = []\n",
    "    y_check_pos = np.array(y_train_val <-2)\n",
    "    for ind,i in enumerate(xdx):\n",
    "        y_pred = clf.predict([X_train_val[i]])  #\n",
    "        if y_pred == -1.0:                          \n",
    "            knn_X = (nn2.kneighbors([X_train_val[i]])[1]).tolist() \n",
    "            for j in knn_X[0]:\n",
    "                y_nn.append(y_train_val[j])    # gom nhãn láng giềng của X_train[i] bị dự đoán sai vào y_nn\n",
    "        else:\n",
    "            y_check_pos[xtl[ind]] = True\n",
    "\n",
    "    y_nn = np.array(y_nn)\n",
    "    if len(y_nn)>0:\n",
    "        y_nn = np.array_split(y_nn, len(y_nn)/n_neighbors)\n",
    "    y_check_neg = np.array(y_train_val <-2)\n",
    "    for i in range(0,len(y_nn)):      #\n",
    "        if 1 not in y_nn[i][1:]:      # Nếu không có nhãn 1 xung quanh X_train[i] bị dự đoán sai => xóa X_train[i]\n",
    "            y_check_neg[xdx[i]] = True\n",
    "\n",
    "    y_check = y_check_neg | y_check_pos\n",
    "    \n",
    "    sample_indices_ = np.flatnonzero(np.logical_not(y_check)) \n",
    "    ytl = _safe_indexing(y_train_val, sample_indices_)\n",
    "    Xtl = _safe_indexing(X_train_val, sample_indices_)\n",
    "    return Xtl,ytl,gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfb(C,namemethod,namefunction,sample_train_val,T,X_train_val,y_train_val,X_test_val, y_test_val,n_neighbors,thamso1,thamso2): #loop find the best\n",
    "    gmean = 0\n",
    "    for i in range(0,T):\n",
    "        print(f\"\\t\\t Vong Lap thu: T = {i+1}\")\n",
    "        #f.write(f\"\\n===================================================================================================================\")\n",
    "        print(f\"\\nSo luong mau training ban dau: {sample_train_val}\")\n",
    "        print(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "        print(len(X_train_val))\n",
    "        X_train_val, y_train_val, gmean2 = data_tomelinks(C,X_train_val,y_train_val,X_test_val, y_test_val,n_neighbors,clf=None,namemethod=namemethod,namefunction=namefunction)\n",
    "        if namefunction == \"exp\":\n",
    "            distribution_weight = compute_weight(X_train_val, y_train_val,name_method = namemethod,name_function = namefunction,beta = 0.5)\n",
    "        else:\n",
    "            distribution_weight = compute_weight(X_train_val, y_train_val,name_method = namemethod,name_function = namefunction)\n",
    "\n",
    "        clf = Wsvm(C,distribution_weight)\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "        print(clf.predict([X_test_val[5]]))\n",
    "        pred2 = clf.predict(X_test_val)    #X_val\n",
    "        sp,se,gmean = Gmean(y_test_val,pred2) #y_val\n",
    "        \n",
    "        metr(X_train_val,y_test_val,pred2,sp,se,gmean)\n",
    "        #metr_text(f,X_train_val,y_test_val,pred2,sp,se,gmean)\n",
    "        \n",
    "        # if ((gmean2 - gmean) <= thamso1) or (gmean2 > thamso2):\n",
    "        #     f.write(\"\\n_____Gmean_ERROR!!!____\\n\")\n",
    "        #     print(\"\\n_____Gmean_ERROR!!!____\\n\")\n",
    "        #     return X_train_val, y_train_val\n",
    "        # else:\n",
    "        #     gmean = gmean2\n",
    "        #f.write(f\"\\n===================================================================================================================\\n\")\n",
    "    return X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr(X_train,y_test,test_pred,se,sp,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    print(\"So luong samples: \",len(X_train))\n",
    "    print(\"\\n\",classification_report(y_test, test_pred))\n",
    "    print(\"SP      : \",sp)\n",
    "    print(\"SE      : \",se)\n",
    "    print(\"Gmean   : \",gmean)\n",
    "    print(\"F1 Score: \",f1_score(y_test, test_pred))\n",
    "    print(\"Accuracy: \",accuracy_score(y_test,test_pred))\n",
    "    print(\"AUC     : \",roc_auc_score(y_test, test_pred))\n",
    "    print(\"Ma tran nham lan: \\n\",confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_lib(X_train, y_train,X_test):\n",
    "    svc=SVC(probability=True, kernel='linear')\n",
    "    model = svc.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 100\n",
    "thamso1 = 1\n",
    "thamso2 = 1\n",
    "T = 2\n",
    "n_neighbors = 5\n",
    "test_size = [0.2,0.3,0.4]\n",
    "testsize_val = 0.2\n",
    "# data = [Co_Author, Abanole, Ecoli, Ecloli1, Ecoli3, Glass1, Glass4, Haberman, Waveform, New_thyroid2, Page_blocks,\n",
    "#             Pima_Indians_Diabetes, Satimage, Transfusion, Yeast]\n",
    "data = [Ecoli]\n",
    "#name_method =[\"estimated_hyper_lin\",\"actual_hyper_lin\",\"own_class_center_opposite\"]\n",
    "name_method =[\"own_class_center_divided\"]\n",
    "name_function = [\"exp\",\"lin_center_own\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "\n",
      "W mac dinh\n",
      "\n",
      "<wsvm.application.Wsvm object at 0x0000025A23124AC8>\n",
      "\n",
      "\n",
      "\tFuzzy W.SVM name_method = 'own_class_center_divided',name_function = 'exp' starting...\n",
      "\n",
      "\t\t Vong Lap thu: T = 1\n",
      "\n",
      "So luong mau training ban dau: 100\n",
      "\n",
      "\n",
      "\tFuzzy W.SVM name_method = 'own_class_center_divided',name_function = 'exp' starting...\n",
      "\n",
      "161\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "BETA:  0.5\n",
      "<wsvm.application.Wsvm object at 0x0000025A23100188>\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "[1.]\n",
      "So luong samples:  154\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.84      0.97      0.90        32\n",
      "         1.0       0.83      0.45      0.59        11\n",
      "\n",
      "    accuracy                           0.84        43\n",
      "   macro avg       0.84      0.71      0.74        43\n",
      "weighted avg       0.84      0.84      0.82        43\n",
      "\n",
      "SP      :  0.96875\n",
      "SE      :  0.45454545454545453\n",
      "Gmean   :  0.663581878211656\n",
      "F1 Score:  0.5882352941176471\n",
      "Accuracy:  0.8372093023255814\n",
      "AUC     :  0.7116477272727273\n",
      "Ma tran nham lan: \n",
      " [[31  1]\n",
      " [ 6  5]]\n",
      "\t\t Vong Lap thu: T = 2\n",
      "\n",
      "So luong mau training ban dau: 100\n",
      "\n",
      "\n",
      "\tFuzzy W.SVM name_method = 'own_class_center_divided',name_function = 'exp' starting...\n",
      "\n",
      "154\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "BETA:  0.5\n",
      "<wsvm.application.Wsvm object at 0x0000025A2311F3C8>\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "[1.]\n",
      "So luong samples:  151\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.86      0.94      0.90        32\n",
      "         1.0       0.75      0.55      0.63        11\n",
      "\n",
      "    accuracy                           0.84        43\n",
      "   macro avg       0.80      0.74      0.76        43\n",
      "weighted avg       0.83      0.84      0.83        43\n",
      "\n",
      "SP      :  0.9375\n",
      "SE      :  0.5454545454545454\n",
      "Gmean   :  0.7150969419341943\n",
      "F1 Score:  0.631578947368421\n",
      "Accuracy:  0.8372093023255814\n",
      "AUC     :  0.7414772727272727\n",
      "Ma tran nham lan: \n",
      " [[30  2]\n",
      " [ 5  6]]\n",
      "DONE!\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "exp\n",
      "So luong samples:  151\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.78      0.82      0.80        68\n",
      "         1.0       0.40      0.33      0.36        24\n",
      "\n",
      "    accuracy                           0.70        92\n",
      "   macro avg       0.59      0.58      0.58        92\n",
      "weighted avg       0.68      0.70      0.69        92\n",
      "\n",
      "SP      :  0.8235294117647058\n",
      "SE      :  0.3333333333333333\n",
      "Gmean   :  0.5239368319955838\n",
      "F1 Score:  0.3636363636363636\n",
      "Accuracy:  0.6956521739130435\n",
      "AUC     :  0.5784313725490196\n",
      "Ma tran nham lan: \n",
      " [[56 12]\n",
      " [16  8]]\n",
      "\n",
      "\n",
      "\tFuzzy W.SVM name_method = 'own_class_center_divided',name_function = 'lin_center_own' starting...\n",
      "\n",
      "\t\t Vong Lap thu: T = 1\n",
      "\n",
      "So luong mau training ban dau: 100\n",
      "\n",
      "\n",
      "\tFuzzy W.SVM name_method = 'own_class_center_divided',name_function = 'lin_center_own' starting...\n",
      "\n",
      "161\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Ko exp\n",
      "<wsvm.application.Wsvm object at 0x0000025A23075B88>\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "[1.]\n",
      "So luong samples:  156\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.83      0.94      0.88        32\n",
      "         1.0       0.71      0.45      0.56        11\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.77      0.70      0.72        43\n",
      "weighted avg       0.80      0.81      0.80        43\n",
      "\n",
      "SP      :  0.9375\n",
      "SE      :  0.45454545454545453\n",
      "Gmean   :  0.6527912098338668\n",
      "F1 Score:  0.5555555555555556\n",
      "Accuracy:  0.813953488372093\n",
      "AUC     :  0.6960227272727273\n",
      "Ma tran nham lan: \n",
      " [[30  2]\n",
      " [ 6  5]]\n",
      "\t\t Vong Lap thu: T = 2\n",
      "\n",
      "So luong mau training ban dau: 100\n",
      "\n",
      "\n",
      "\tFuzzy W.SVM name_method = 'own_class_center_divided',name_function = 'lin_center_own' starting...\n",
      "\n",
      "156\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Ko exp\n",
      "<wsvm.application.Wsvm object at 0x0000025A23075B88>\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "[1.]\n",
      "So luong samples:  153\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.84      0.97      0.90        32\n",
      "         1.0       0.83      0.45      0.59        11\n",
      "\n",
      "    accuracy                           0.84        43\n",
      "   macro avg       0.84      0.71      0.74        43\n",
      "weighted avg       0.84      0.84      0.82        43\n",
      "\n",
      "SP      :  0.96875\n",
      "SE      :  0.45454545454545453\n",
      "Gmean   :  0.663581878211656\n",
      "F1 Score:  0.5882352941176471\n",
      "Accuracy:  0.8372093023255814\n",
      "AUC     :  0.7116477272727273\n",
      "Ma tran nham lan: \n",
      " [[31  1]\n",
      " [ 6  5]]\n",
      "DONE!\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "Ko exp\n",
      "So luong samples:  153\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.78      0.82      0.80        68\n",
      "         1.0       0.40      0.33      0.36        24\n",
      "\n",
      "    accuracy                           0.70        92\n",
      "   macro avg       0.59      0.58      0.58        92\n",
      "weighted avg       0.68      0.70      0.69        92\n",
      "\n",
      "SP      :  0.8235294117647058\n",
      "SE      :  0.3333333333333333\n",
      "Gmean   :  0.5239368319955838\n",
      "F1 Score:  0.3636363636363636\n",
      "Accuracy:  0.6956521739130435\n",
      "AUC     :  0.5784313725490196\n",
      "Ma tran nham lan: \n",
      " [[56 12]\n",
      " [16  8]]\n"
     ]
    }
   ],
   "source": [
    "X_train_val, y_train_val, X_test_val, y_test_val, X_test, y_test = Haberman.load_data(test_size=0.3,testsize_val=0.2)\n",
    "distribution_weight = compute_weight(X_train_val, y_train_val)\n",
    "#pred = wsvm(C,X_train_val, y_train_val, X_test, distribution_weight)\n",
    "#print(pred),\n",
    "X_train_tl, y_train_tl,_ = data_tomelinks(C,X_train_val,y_train_val,X_test_val, y_test_val, n_neighbors)\n",
    "for namemethod in name_method:\n",
    "    for namefunction in name_function:\n",
    "        print(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "        X_train_new, y_train_new = lfb(C,namemethod,namefunction,100, T, X_train_tl,y_train_tl,X_test_val, y_test_val, n_neighbors, thamso1,thamso2) \n",
    "        print(\"DONE!\")\n",
    "        if namefunction == \"exp\":\n",
    "            distribution_weight = compute_weight(X_train_new, y_train_new,name_method = namemethod,name_function = namefunction,beta = 0.5)\n",
    "            print(\"exp\")\n",
    "        else:\n",
    "            distribution_weight = compute_weight(X_train_new, y_train_new,name_method = namemethod,name_function = namefunction)\n",
    "            print(\"Ko exp\")\n",
    "        test_pred_tl = wsvm(C,X_train_new, y_train_new, X_test, distribution_weight)\n",
    "        sp,se,gmean = Gmean(y_test, test_pred_tl)\n",
    "        metr(X_train_new, y_test, test_pred_tl, sp, se, gmean)\n",
    "        # se,sp,gmean = Gmean(y_test,pred)\n",
    "\n",
    "        # metr(X_train_val,y_test,pred,se,sp,gmean)\n",
    "# # ##\n",
    "# pred2 = svm_lib(X_train_val, y_train_val,X_test)\n",
    "# se2,sp2,gmean2 = Gmean(y_test,pred2)\n",
    "# print(\"SVM LIBRA\")\n",
    "# metr(X_train_val,y_test,pred2,se2,sp2,gmean2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, y_train_val, X_test_val, y_test_val, X_test, y_test = Haberman.load_data(test_size=0.3,testsize_val=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.33055036e-01,1.93256405e-01,8.46084996e-02,9.85577407e-02\n",
    ",7.96895456e-02,1.27073435e-01,9.27549131e-02,1.89629000e-01\n",
    ",1.08111890e-02,6.47346953e-02,1.28877815e-05,3.97741828e-02\n",
    ",1.06404151e-01,4.28457738e-02,6.06627497e-02,2.11256646e-01\n",
    ",5.36435647e-02,6.22377880e-02,1.11848432e-01,3.23473302e-02\n",
    ",1.28507204e-01,1.45773927e-01,1.66158203e-01,6.13615969e-02\n",
    ",9.76827180e-02,1.72950670e-01,6.25965561e-02,6.75673283e-02\n",
    ",1.97751989e-01,1.28877815e-05,8.30779970e-02,4.90421633e-02\n",
    ",1.45621320e-01,2.13640597e-01,3.75383181e-02,2.79424730e-02\n",
    ",4.37741111e-02,8.11388228e-02,1.71303364e-01,3.33532377e-02\n",
    ",7.20919354e-02,6.87193247e-03,6.36242832e-02,1.61821630e-01\n",
    ",1.28168402e-01,3.53577897e-01,1.60653967e-01,1.53248259e-01\n",
    ",1.58413159e-01,1.68008902e-01,1.70503123e-01,1.62172887e-01\n",
    ",1.55441986e-01,1.60363729e-01,1.60133726e-01,1.57614649e-01\n",
    ",1.61399541e-01,1.62897180e-01,1.57965419e-01,1.67537178e-01\n",
    ",1.35493029e-01,1.61060379e-01,1.67024782e-01,1.64162494e-01\n",
    ",1.50100637e-01,1.61895991e-01,1.60787421e-01,1.43440819e-01\n",
    ",1.66859123e-01,1.61063276e-01,1.65517066e-01,1.53369570e-01\n",
    ",1.56916030e-01,1.47864485e-01,1.63929393e-01,1.64046322e-01\n",
    ",1.63657759e-01,1.38879313e-01,1.69651894e-01,1.69742989e-01\n",
    ",1.60438207e-01,1.56930969e-01,1.61614628e-01,1.55043116e-01\n",
    ",1.55576971e-01,1.64892436e-01,1.71251448e-01,1.55584613e-01\n",
    ",1.61779767e-01,1.67121407e-01,1.57254511e-01,1.56697578e-01\n",
    ",1.62998742e-01,1.51318301e-01,1.55900624e-01,1.59115620e-01\n",
    ",1.65245780e-01,1.66940509e-01,1.67049737e-01,1.62751039e-01\n",
    ",1.59291410e-01,1.56485386e-01,1.64255944e-01,1.61063276e-01\n",
    ",1.47265687e-01,1.58665056e-01,1.56902914e-01,1.61063276e-01\n",
    ",1.60758193e-01,1.67233789e-01,1.58963596e-01,1.63478432e-01\n",
    ",1.68559237e-01,1.44938482e-01,1.56822154e-01,1.68624785e-01\n",
    ",1.63950409e-01,1.57381718e-01,1.59105683e-01,1.60663889e-01\n",
    ",1.61143961e-01,1.66517834e-01,1.58467006e-01,1.56288332e-01\n",
    ",1.59925351e-01,1.57697474e-01,1.62950309e-01,1.58187375e-01\n",
    ",1.68465301e-01,1.60229111e-01,1.59895857e-01,1.71381867e-01\n",
    ",1.54097851e-01,1.64149711e-01,1.65457750e-01,1.72386233e-01\n",
    ",1.39139314e-01,1.70503123e-01,1.55311220e-01,3.31842152e-06\n",
    ",1.61198458e-01,1.52327022e-01,1.62563452e-01,1.61394091e-01\n",
    ",1.55711533e-01,1.72588445e-01,1.57965419e-01,1.55277397e-01\n",
    ",1.66940509e-01,1.53571353e-01,1.45246122e-01,1.50451351e-01\n",
    ",1.50075386e-01,1.58509082e-01,1.62864875e-01,1.57934165e-01\n",
    ",1.58347444e-01,1.54207189e-01,1.72929353e-01,1.62227270e-01\n",
    ",1.57781957e-01,1.71017370e-01,1.60154206e-01,1.58619705e-01\n",
    ",1.57781957e-01,1.71017370e-01,1.60154206e-01,1.58619705e-01,\n",
    "1.57781957e-01,1.71017370e-01,1.60154206e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wsvm.application.Wsvm object at 0x0000025A2311FF48>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (153,) (171,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a41d849f9742>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcvv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWsvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdistribution_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcvv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcvv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Fuzzy\\fuzzy_svm\\wsvm\\application.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# print(type(self.distribution_weight))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_problem_quadratic_program\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m#Solve Quadratic Program\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0msol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_problem_quadratic_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Fuzzy\\fuzzy_svm\\wsvm\\methods.py\u001b[0m in \u001b[0;36mdual_problem_quadratic_program\u001b[1;34m(X, y, C, distribution_weights)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m#print(\"weight: \",distribution_weights)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistribution_weights\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (153,) (171,) "
     ]
    }
   ],
   "source": [
    "cvv = Wsvm(C,distribution_weight)\n",
    "print(cvv)\n",
    "cvv.fit(X_train_val, y_train_val)\n",
    "cvv.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183bbf6827d058c2a2fb0f4acdc0420849dda2b4380af0e437e38c64d798d8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
