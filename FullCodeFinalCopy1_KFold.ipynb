{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.20356986, -0.23616822, -0.01535438, ..., -0.10297836,\n",
      "        -0.00333545,  1.9115189 ],\n",
      "       [-0.71319985, -0.07417361,  0.33070229, ..., -0.10297836,\n",
      "        -1.03616576, -0.16111872],\n",
      "       [-0.42198271,  0.16881831, -1.05352439, ..., -0.10297836,\n",
      "         0.16880293, -0.53796193],\n",
      "       ...,\n",
      "       [ 0.59727728,  0.08782101,  0.67675896, ..., -0.10297836,\n",
      "        -2.75754961, -0.53796193],\n",
      "       [-0.13076557, -0.39816283,  1.48422452, ..., -0.10297836,\n",
      "         1.37377162, -0.53796193],\n",
      "       [ 0.014843  ,  0.08782101,  0.79211118, ..., -0.10297836,\n",
      "        -0.34761222, -0.53796193]]), array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
      "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1],\n",
      "      dtype=int64), array([[ 0.67008156,  1.2217833 ,  0.21535006, ..., -0.10297836,\n",
      "        -0.69188899,  0.30993528],\n",
      "       [-2.24208984, -0.72215206,  0.56140673, ..., -0.10297836,\n",
      "         0.34094132, -0.25532953],\n",
      "       [-1.58685127, -0.31716553, -2.78380773, ..., -0.10297836,\n",
      "        -1.89685769, -0.53796193],\n",
      "       ...,\n",
      "       [ 0.37886442,  0.24981562,  0.67675896, ..., -0.10297836,\n",
      "        -0.34761222, -0.53796193],\n",
      "       [-0.494787  , -0.64115475,  0.44605451, ..., -0.10297836,\n",
      "         1.20163324,  0.49835688],\n",
      "       [-0.494787  ,  0.08782101,  0.44605451, ..., -0.10297836,\n",
      "        -0.86402738, -0.16111872]]), array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "      dtype=int64), array([[-0.64039557, -0.39816283,  0.33070229, ..., -0.10297836,\n",
      "         0.16880293, -0.25532953],\n",
      "       [-0.13076557,  0.65480215, -0.36141105, ..., -0.10297836,\n",
      "         0.5130797 ,  4.36099973],\n",
      "       [-1.9508727 , -2.4230955 ,  0.33070229, ..., -0.10297836,\n",
      "        -1.03616576, -0.53796193],\n",
      "       ...,\n",
      "       [-0.05796129,  0.16881831,  0.33070229, ..., -0.10297836,\n",
      "         0.16880293, -0.53796193],\n",
      "       [ 0.014843  , -0.31716553,  0.21535006, ..., -0.10297836,\n",
      "         0.34094132, -0.16111872],\n",
      "       [ 0.67008156,  1.38377791,  0.67675896, ..., -0.10297836,\n",
      "        -0.51975061, -0.53796193]]), array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
      "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data import Vertebral_column\n",
    "from data import Co_Author\n",
    "from Processing_Data import Abanole\n",
    "from Processing_Data import Ecoli\n",
    "from Processing_Data import Ecloli1\n",
    "from Processing_Data import Ecoli3\n",
    "from Processing_Data import Glass1\n",
    "from Processing_Data import Glass4\n",
    "from Processing_Data import Haberman\n",
    "from Processing_Data import Waveform\n",
    "from Processing_Data import New_thyroid2\n",
    "from Processing_Data import Page_blocks\n",
    "from Processing_Data import Pima_Indians_Diabetes\n",
    "from Processing_Data import Satimage\n",
    "from Processing_Data import Transfusion\n",
    "from Processing_Data import Yeast\n",
    "from Processing_Data import Transfution_Kfold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data import indian_liver_patient\n",
    "#from data import spect_heart\n",
    "from wsvm.application import Wsvm\n",
    "from svm.application import Svm\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.metrics import f1_score\n",
    "from sklearn.metrics  import classification_report,precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from datetime import datetime\n",
    "from fuzzy.weight import fuzzy\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_lib(X_train, y_train,X_test):\n",
    "    svc=SVC(probability=True, kernel='linear')\n",
    "    model = svc.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsvm(C,X_train, y_train,X_test,distribution_weight=None):\n",
    "    model = Wsvm(C,distribution_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(C,X_train, y_train,X_test):\n",
    "    model = Svm(C)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tomek(X,y, class_type):\n",
    "    nn = NearestNeighbors(n_neighbors=2)\n",
    "    nn.fit(X)\n",
    "    nn_index = nn.kneighbors(X, return_distance=False)[:, 1]\n",
    "    links = np.zeros(len(y), dtype=bool)\n",
    "    # find which class to not consider\n",
    "    class_excluded = [c for c in np.unique(y) if c not in class_type]\n",
    "    X_dangxet = []\n",
    "    X_tl = []\n",
    "    # there is a Tomek link between two samples if they are both nearest\n",
    "    # neighbors of each others.\n",
    "    for index_sample, target_sample in enumerate(y):\n",
    "        if target_sample in class_excluded:\n",
    "            continue\n",
    "        if y[nn_index[index_sample]] != target_sample:\n",
    "            if nn_index[nn_index[index_sample]] == index_sample:\n",
    "                X_tl.append(index_sample)\n",
    "                X_dangxet.append(nn_index[index_sample])\n",
    "                links[index_sample] = True\n",
    "\n",
    "    return links,X_dangxet,X_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gmean(y_test,y_pred):\n",
    "    cm_WSVM = metrics.confusion_matrix(y_test, y_pred)\n",
    "    sensitivity = cm_WSVM[1,1]/(cm_WSVM[1,0]+cm_WSVM[1,1])\n",
    "    specificity = cm_WSVM[0,0]/(cm_WSVM[0,0]+cm_WSVM[0,1])\n",
    "    gmean = math.sqrt(sensitivity*specificity)\n",
    "    return specificity,sensitivity,gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr(X_train,y_test,test_pred,sp,se,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    print(\"So luong samples: \",len(X_train))\n",
    "    print(\"\\n\",classification_report(y_test, test_pred))\n",
    "    print(\"SP      : \",sp)\n",
    "    print(\"SE      : \",se)\n",
    "    print(\"Gmean   : \",gmean)\n",
    "    print(\"F1 Score: \",f1_score(y_test, test_pred))\n",
    "    print(\"Accuracy: \",accuracy_score(y_test,test_pred))\n",
    "    print(\"AUC     : \",roc_auc_score(y_test, test_pred))\n",
    "    print(\"Ma tran nham lan: \\n\",confusion_matrix(y_test, test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr_text(f,X_train,y_test,test_pred,sp,se,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    f.write(f\"\\n\\nSo luong samples Tong: {len(X_train)+len(y_test)}\")\n",
    "    f.write(f\"\\n\\nSo luong samples training: {len(X_train)}\")\n",
    "    f.write(f\"\\nSo luong samples testing: {len(y_test)}\\n\")\n",
    "    f.write(\"\\n\"+str(classification_report(y_test, test_pred)))\n",
    "    f.write(f\"\\nSP      : {sp:0.4f}\")\n",
    "    f.write(f\"\\nSE      : {se:0.4f}\")\n",
    "    f.write(f\"\\nGmean   : {gmean:0.4f}\")\n",
    "    f.write(f\"\\nF1 Score: {f1_score(y_test, test_pred):0.4f}\")\n",
    "    f.write(f\"\\nAccuracy: {accuracy_score(y_test,test_pred):0.4f}\")\n",
    "    f.write(f\"\\nAUC     : {roc_auc_score(y_test, test_pred):0.4f}\")\n",
    "    f.write(\"\\n\\nMa tran nham lan: \\n\"+str(confusion_matrix(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(X, y,name_method =\"actual_hyper_lin\", name_function = \"exp\", beta = None,C = None, gamma = None, u = None, sigma = None):\n",
    "    method = fuzzy.method()\n",
    "    function = fuzzy.function()\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    try:\n",
    "        if name_method == \"own_class_center\": \n",
    "            d = method.own_class_center(X, y)\n",
    "        elif name_method == \"estimated_hyper_lin\": # actual_hyper_lin, own_class_center\n",
    "            d = method.estimated_hyper_lin(X, y)\n",
    "        elif name_method == \"own_class_center_opposite\":\n",
    "            d = method.own_class_center_opposite(X, y)\n",
    "        elif name_method == 'actual_hyper_lin':\n",
    "            d = method.actual_hyper_lin(X, y,C = C, gamma = gamma)\n",
    "        elif name_method == 'own_class_center_divided':\n",
    "            d = method.own_class_center_divided(X, y)\n",
    "        elif name_method == \"distance_center_own_opposite_tam\":\n",
    "            d_own, d_opp, d_tam = method.distance_center_own_opposite_tam(X,y)\n",
    "        else:\n",
    "            print('dont exist method')\n",
    "        \n",
    "        if name_function == \"lin\":\n",
    "            W = function.lin(d)\n",
    "        elif name_function == \"exp\":\n",
    "            W = function.exp(d, beta)\n",
    "        elif name_function == \"lin_center_own\":\n",
    "            W = function.lin_center_own(d, pos_index,neg_index)\n",
    "        elif name_function == 'gau':\n",
    "            W = function.gau(d, u, sigma)\n",
    "        elif name_function == \"func_own_opp_new\":\n",
    "            W = function.func_own_opp_new(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "    except Exception as e:\n",
    "        print('dont exist function')\n",
    "        print(e)\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    r_pos = 1\n",
    "    r_neg = len(pos_index)/len(neg_index)\n",
    "    m = []\n",
    "    W = np.array(W)\n",
    "    m = W[pos_index]*r_pos\n",
    "    m = np.append(m, W[neg_index]*r_neg)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_opp(X,y):\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    method = fuzzy.method()\n",
    "    function = fuzzy.function()\n",
    "    d_own, d_opp, d_tam = method.distance_center_own_opposite_tam(X,y)\n",
    "    W = function.func_own_opp_new(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction):\n",
    "    if namemethod ==\"own_class_center_opposite\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_center)\n",
    "        f.write(f\"\\n\\t Beta 'own_class_center_opposite' with exp = {beta_center}\\n\")\n",
    "    elif namemethod ==\"own_class_center\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "        f.write(f\"\\n\\t Beta 'own_class_center' with exp = {beta_center}\\n\")\n",
    "    elif namemethod ==\"own_class_center_divided\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "        f.write(f\"\\n\\t Beta 'own_class_center_divided' with exp = {beta_center}\\n\")\n",
    "    elif namemethod ==\"estimated_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "        f.write(f\"\\n\\t Beta 'estimated_hyper_lin' with exp = {beta_estimate}\\n\")\n",
    "    elif namemethod ==\"actual_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_actual)\n",
    "        f.write(f\"\\n\\t Beta 'actual_hyper_lin' with exp = {beta_actual}\\n\")\n",
    "    else:   \n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction)\n",
    "    return distribution_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tomelinks(f,C,X_train_val,y_train_val,X_test_val, y_test_val,n_neighbors,clf=None,namemethod=None,namefunction=None):\n",
    "    links,xdx,xtl = is_tomek(X_train_val,y_train_val,class_type=[-1.0])\n",
    "    if clf == None:\n",
    "        if namemethod == None:\n",
    "            distribution_weight = compute_weight(X_train_val, y_train_val)\n",
    "        else:\n",
    "            distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train_val, y_train_val,namemethod,namefunction)\n",
    "        clf = Wsvm(C,distribution_weight)\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "    else:\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "    y_predict = clf.predict(X_test_val)\n",
    "    sensitivity,specificity,gmean = Gmean(y_test_val,y_predict)\n",
    "    nn2 = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn2.fit(X_train_val)\n",
    "    y_nn = []\n",
    "    y_check_pos = np.array(y_train_val <-2)\n",
    "    for ind,i in enumerate(xdx):\n",
    "        y_pred = clf.predict([X_train_val[i]])  #\n",
    "        if y_pred == -1.0:                          \n",
    "            knn_X = (nn2.kneighbors([X_train_val[i]])[1]).tolist() \n",
    "            for j in knn_X[0]:\n",
    "                y_nn.append(y_train_val[j])    # gom nhãn láng giềng của X_train[i] bị dự đoán sai vào y_nn\n",
    "        else:\n",
    "            y_check_pos[xtl[ind]] = True\n",
    "\n",
    "    y_nn = np.array(y_nn)\n",
    "    if len(y_nn)>0:\n",
    "        y_nn = np.array_split(y_nn, len(y_nn)/n_neighbors)\n",
    "    y_check_neg = np.array(y_train_val <-2)\n",
    "    for i in range(0,len(y_nn)):      #\n",
    "        if 1 not in y_nn[i][1:]:      # Nếu không có nhãn 1 xung quanh X_train[i] bị dự đoán sai => xóa X_train[i]\n",
    "            y_check_neg[xdx[i]] = True\n",
    "\n",
    "    y_check = y_check_neg | y_check_pos\n",
    "    \n",
    "    sample_indices_ = np.flatnonzero(np.logical_not(y_check)) \n",
    "    ytl = _safe_indexing(y_train_val, sample_indices_)\n",
    "    Xtl = _safe_indexing(X_train_val, sample_indices_)\n",
    "    return Xtl,ytl,gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "for n_neighbors in range(5,4,-1):\n",
    "    print(n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfb(f,C,dataset,namemethod,namefunction,sample_train_val,T,X_train_val,y_train_val,X_test_val, y_test_val,n_neighbors,thamso1,thamso2): #loop find the best\n",
    "    gmean = 0\n",
    "    for i in range(0,T):\n",
    "        f.write(f\"\\t\\t Vong Lap thu: T = {i+1}\")\n",
    "        f.write(f\"\\n===================================================================================================================\")\n",
    "        f.write(f\"\\n\\n\\tFuzzy SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "        f.write(f\"\\nSo luong mau training_val ban dau: {sample_train_val}\")\n",
    "        X_train_val, y_train_val, gmean2 = data_tomelinks(f,C,X_train_val,y_train_val,X_test_val, y_test_val,n_neighbors,clf=None,namemethod=namemethod,namefunction=namefunction)\n",
    "        distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train_val, y_train_val,namemethod,namefunction)\n",
    "        clf = Wsvm(C,distribution_weight)\n",
    "        #print(X_train_val)\n",
    "        #print(y_train_val)\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "        #print(clf.predict([X_test_val[5]]))\n",
    "        pred2 = clf.predict(X_test_val)    #X_val\n",
    "        sp,se,gmean = Gmean(y_test_val,pred2) #y_val\n",
    "        \n",
    "        #metr(X_train_val,y_test_val,pred2,sp,se,gmean)\n",
    "        metr_text(f,X_train_val,y_test_val,pred2,sp,se,gmean)\n",
    "        \n",
    "        # if ((gmean2 - gmean) <= thamso1) or (gmean2 > thamso2):\n",
    "        #     f.write(\"\\n_____Gmean_ERROR!!!____\\n\")\n",
    "        #     print(\"\\n_____Gmean_ERROR!!!____\\n\")\n",
    "        #     return X_train_val, y_train_val\n",
    "        # else:\n",
    "        #     gmean = gmean2\n",
    "        f.write(f\"\\n===================================================================================================================\\n\")\n",
    "    return X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy W.SVM name_method = 'own_class_center',name_function = 'lin_center_own' starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy W.SVM name_method = 'own_class_center',name_function = 'exp' starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy W.SVM name_method = 'estimated_hyper_lin',name_function = 'lin_center_own' starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy W.SVM name_method = 'estimated_hyper_lin',name_function = 'exp' starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy W.SVM name_method = 'actual_hyper_lin',name_function = 'lin_center_own' starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy W.SVM name_method = 'actual_hyper_lin',name_function = 'exp' starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\FSVM_CIL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "C = 100\n",
    "thamso1 = 1\n",
    "thamso2 = 1\n",
    "T = 3\n",
    "n_neighbors = 5\n",
    "test_size = [0.2,0.3,0.4]\n",
    "testsize_val = 0.2\n",
    "# data = [Co_Author, Abanole, Ecoli, Ecloli1, Ecoli3, Glass1, Glass4, Haberman, Waveform, New_thyroid2, Page_blocks,\n",
    "# #             Pima_Indians_Diabetes, Satimage, Transfusion, Yeast]\n",
    "# data = [Haberman]\n",
    "# data = [Pima_Indians_Diabetes]\n",
    "# data = [Transfusion]\n",
    "# data = [Ecoli]\n",
    "# data = [Abanole]\n",
    "# data = [Yeast]\n",
    "data = [Transfution_Kfold]\n",
    "# !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!!\n",
    "beta_center, beta_estimate, beta_actual = 0.5, 0.8, 0.1 # !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!!\n",
    "# !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!\n",
    "\n",
    "name_method =[\"own_class_center\",\"estimated_hyper_lin\",\"actual_hyper_lin\",\"distance_center_own_opposite_tam\"]\n",
    "#name_method =[\"own_class_center_divided\"]\n",
    "name_function = [\"lin_center_own\",\"exp\",\"func_own_opp_new\"]\n",
    "\n",
    "time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "filepath = \"./text_script\"\n",
    "\n",
    "#svc lib\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "#svm scratch\n",
    "svm_scr = Svm(C)\n",
    "#W.svm\n",
    "\n",
    "for dataset in data:\n",
    "    filename = (str(dataset).split(\"\\\\\")[-1]).split(\".\")[0]\n",
    "    f = open(f\"{filepath}/Data_{filename}_{time}_Detail.txt\", \"w\")\n",
    "    f.write(f\"\\nC = {C}, thamso1 = {thamso1}, thamso2 = {thamso2}, T = {T}, n_neighbors = {n_neighbors}  \\n\")\n",
    "    f.write(f\"\\n\\n\\tUSING DATASET : {filename}\\n\")\n",
    "\n",
    "    f2 = open(f\"{filepath}/Data_{filename}_{time}_Main.txt\", \"w\")\n",
    "    f2.write(f\"\\nC = {C}, thamso1 = {thamso1}, thamso2 = {thamso2}, T = {T}, n_neighbors = {n_neighbors}  \\n\")\n",
    "    f2.write(f\"\\n\\n\\tUSING DATASET : {filename}\\n\")\n",
    "    \n",
    "    # X_train, X_test,y_train, y_test = dataset.load_data()\n",
    "    \n",
    "    X, y = dataset.load_data()\n",
    "    kfold_validation = KFold(n_splits=10, shuffle=True)\n",
    "    for train_index, test_index in kfold_validation.split(X):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        #Scalling Data\n",
    "        sc_X = StandardScaler()\n",
    "        X_train = sc_X.fit_transform(X_train)\n",
    "        X_test = sc_X.transform(X_test)\n",
    "        #Svm library\n",
    "        f.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "        f2.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "        #print(\"SVM LIBRARY starting...\\n\")\n",
    "        test_pred = svm_lib(X_train, y_train,X_test)\n",
    "        sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        #Svm scratch\n",
    "        f.write(\"\\n\\n\\tSVM starting...\\n\")\n",
    "        f2.write(\"\\n\\n\\tSVM starting...\\n\")\n",
    "        print(\"SVM starting...\\n\")\n",
    "        test_pred = svm(C,X_train, y_train,X_test)\n",
    "        sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        #Wsvm\n",
    "        f.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "        f2.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "        #print(\"W.SVM starting...\\n\")\n",
    "        N, d = X_train.shape\n",
    "        distribution_weight = np.ones(N)\n",
    "        test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "        sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        #FuzyyWsvm\n",
    "        for namemethod in name_method:\n",
    "            for namefunction in name_function:\n",
    "                if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"func_own_opp_new\":\n",
    "                    f.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    f2.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    distribution_weight2 = own_opp(X_train, y_train)\n",
    "                    test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight2)\n",
    "                    sp2,se2,gmean2 = Gmean(y_test,test_pred)\n",
    "                    metr_text(f,X_train,y_test,test_pred,sp2,se2,gmean2)\n",
    "                    metr_text(f2,X_train,y_test,test_pred,sp2,se2,gmean2)\n",
    "                elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "                    continue\n",
    "                elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "                    continue\n",
    "                elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                else:\n",
    "                    f.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    f2.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                    __ = fuzzy_weight(f2,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                    test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "                    sp,se,gmean = Gmean(y_test,test_pred)\n",
    "                    #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "                    metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "                    metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "\n",
    "\n",
    "    # kfold_validation = KFold(n_splits=10, shuffle=True)\n",
    "    # for train_index, test_index in kfold_validation.split(X):\n",
    "    #     X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    #     X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "    #     #Scalling Data\n",
    "    #     sc_X = StandardScaler()\n",
    "    #     X_train = sc_X.fit_transform(X_train)\n",
    "    #     X_test = sc_X.transform(X_test)\n",
    "\n",
    "    #     #Svm library\n",
    "    #     f.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "    #     f2.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "    #     #print(\"SVM LIBRARY starting...\\n\")\n",
    "    #     test_pred = svm_lib(X_train, y_train,X_test)\n",
    "    #     sp,se,gmean = Gmean(y_test,test_pred)\n",
    "    #     #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "    #     metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "    #     metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "    #     #Svm scratch\n",
    "    #     f.write(\"\\n\\n\\tSVM starting...\\n\")\n",
    "    #     f2.write(\"\\n\\n\\tSVM starting...\\n\")\n",
    "    #     print(\"SVM starting...\\n\")\n",
    "    #     test_pred = svm(C,X_train, y_train,X_test)\n",
    "    #     sp,se,gmean = Gmean(y_test,test_pred)\n",
    "    #     #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "    #     metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "    #     metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "    #     #Wsvm\n",
    "    #     f.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "    #     f2.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "    #     #print(\"W.SVM starting...\\n\")\n",
    "    #     N, d = X_train.shape\n",
    "    #     distribution_weight = np.ones(N)\n",
    "    #     test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "    #     sp,se,gmean = Gmean(y_test,test_pred)\n",
    "    #     #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "    #     metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "    #     metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "    #     #FuzyyWsvm\n",
    "    #     for namemethod in name_method:\n",
    "    #         for namefunction in name_function:\n",
    "    #             if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"func_own_opp_new\":\n",
    "    #                 f.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "    #                 f2.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "    #                 distribution_weight2 = own_opp(X_train, y_train)\n",
    "    #                 test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight2)\n",
    "    #                 sp2,se2,gmean2 = Gmean(y_test,test_pred)\n",
    "    #                 metr_text(f,X_train,y_test,test_pred,sp2,se2,gmean2)\n",
    "    #                 metr_text(f2,X_train,y_test,test_pred,sp2,se2,gmean2)\n",
    "    #             elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "    #                 continue\n",
    "    #             elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "    #                 continue\n",
    "    #             elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "    #                 continue\n",
    "    #             elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "    #                 continue\n",
    "    #             elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "    #                 continue\n",
    "    #             else:\n",
    "    #                 f.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "    #                 f2.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "    #                 print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "    #                 distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "    #                 __ = fuzzy_weight(f2,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "    #                 test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "    #                 sp,se,gmean = Gmean(y_test,test_pred)\n",
    "    #                 #metr(X_train_val,y_test,test_pred,sp,se,gmean)\n",
    "    #                 metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "    #                 metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "    f.write(\"\\n===================================================================================\\n\")\n",
    "    f.close()\n",
    "    f2.write(\"\\n===================================================================================\\n\")\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()\n",
    "f2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FSVM-CIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd073cf77417f2eda899b4964833636dfa63b2ff098a61069509a2b01c748e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
