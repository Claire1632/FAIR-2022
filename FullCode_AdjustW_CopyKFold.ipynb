{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.20356986, -0.23616822, -0.01535438, ..., -0.10297836,\n",
      "        -0.00333545,  1.9115189 ],\n",
      "       [-0.71319985, -0.07417361,  0.33070229, ..., -0.10297836,\n",
      "        -1.03616576, -0.16111872],\n",
      "       [-0.42198271,  0.16881831, -1.05352439, ..., -0.10297836,\n",
      "         0.16880293, -0.53796193],\n",
      "       ...,\n",
      "       [ 0.59727728,  0.08782101,  0.67675896, ..., -0.10297836,\n",
      "        -2.75754961, -0.53796193],\n",
      "       [-0.13076557, -0.39816283,  1.48422452, ..., -0.10297836,\n",
      "         1.37377162, -0.53796193],\n",
      "       [ 0.014843  ,  0.08782101,  0.79211118, ..., -0.10297836,\n",
      "        -0.34761222, -0.53796193]]), array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
      "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1],\n",
      "      dtype=int64), array([[ 0.67008156,  1.2217833 ,  0.21535006, ..., -0.10297836,\n",
      "        -0.69188899,  0.30993528],\n",
      "       [-2.24208984, -0.72215206,  0.56140673, ..., -0.10297836,\n",
      "         0.34094132, -0.25532953],\n",
      "       [-1.58685127, -0.31716553, -2.78380773, ..., -0.10297836,\n",
      "        -1.89685769, -0.53796193],\n",
      "       ...,\n",
      "       [ 0.37886442,  0.24981562,  0.67675896, ..., -0.10297836,\n",
      "        -0.34761222, -0.53796193],\n",
      "       [-0.494787  , -0.64115475,  0.44605451, ..., -0.10297836,\n",
      "         1.20163324,  0.49835688],\n",
      "       [-0.494787  ,  0.08782101,  0.44605451, ..., -0.10297836,\n",
      "        -0.86402738, -0.16111872]]), array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "      dtype=int64), array([[-0.64039557, -0.39816283,  0.33070229, ..., -0.10297836,\n",
      "         0.16880293, -0.25532953],\n",
      "       [-0.13076557,  0.65480215, -0.36141105, ..., -0.10297836,\n",
      "         0.5130797 ,  4.36099973],\n",
      "       [-1.9508727 , -2.4230955 ,  0.33070229, ..., -0.10297836,\n",
      "        -1.03616576, -0.53796193],\n",
      "       ...,\n",
      "       [-0.05796129,  0.16881831,  0.33070229, ..., -0.10297836,\n",
      "         0.16880293, -0.53796193],\n",
      "       [ 0.014843  , -0.31716553,  0.21535006, ..., -0.10297836,\n",
      "         0.34094132, -0.16111872],\n",
      "       [ 0.67008156,  1.38377791,  0.67675896, ..., -0.10297836,\n",
      "        -0.51975061, -0.53796193]]), array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
      "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "       -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data import Vertebral_column\n",
    "from data import Co_Author\n",
    "from Processing_Data import Abanole\n",
    "from Processing_Data import Ecoli\n",
    "from Processing_Data import Ecloli1\n",
    "from Processing_Data import Ecoli3\n",
    "from Processing_Data import Glass1\n",
    "from Processing_Data import Glass4\n",
    "from Processing_Data import Haberman\n",
    "from Processing_Data import Waveform\n",
    "from Processing_Data import New_thyroid2\n",
    "from Processing_Data import Page_blocks\n",
    "from Processing_Data import Pima_Indians_Diabetes\n",
    "from Processing_Data import Satimage\n",
    "from Processing_Data import Transfusion\n",
    "from Processing_Data import Yeast\n",
    "from Processing_Data import Haberman_All\n",
    "from Processing_Data import Transfusion_All\n",
    "from Processing_Data import PimaIndians_All\n",
    "from data import indian_liver_patient\n",
    "#from data import spect_heart\n",
    "from wsvm.application import Wsvm\n",
    "from svm.application import Svm\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.metrics import f1_score\n",
    "from sklearn.metrics  import classification_report,precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from datetime import datetime\n",
    "from fuzzy.weight import fuzzy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Processing_Data import Ecoli_Kfold\n",
    "from Processing_Data import Haberman_KFold\n",
    "from Processing_Data import Transfution_Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_lib(X_train, y_train,X_test):\n",
    "    svc=SVC(probability=True, kernel='linear')\n",
    "    model = svc.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsvm(C,X_train, y_train,X_test,distribution_weight=None):\n",
    "    model = Wsvm(C,distribution_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(C,X_train, y_train,X_test):\n",
    "    model = Svm(C)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tomek(X,y, class_type):\n",
    "    print(y)\n",
    "    print(type(y))\n",
    "    nn = NearestNeighbors(n_neighbors=2)\n",
    "    nn.fit(X)\n",
    "    nn_index = nn.kneighbors(X, return_distance=False)[:, 1]\n",
    "    links = np.zeros(len(y), dtype=bool)\n",
    "    # find which class to not consider\n",
    "    class_excluded = [c for c in np.unique(y) if c not in class_type]\n",
    "    X_dangxet = []\n",
    "    X_tl = []\n",
    "    # there is a Tomek link between two samples if they are both nearest\n",
    "    # neighbors of each others.\n",
    "    for index_sample, target_sample in enumerate(y):\n",
    "        if target_sample in class_excluded:\n",
    "            continue\n",
    "        if y[nn_index[index_sample]] != target_sample:\n",
    "            if nn_index[nn_index[index_sample]] == index_sample:\n",
    "                X_tl.append(index_sample)\n",
    "                X_dangxet.append(nn_index[index_sample])\n",
    "                links[index_sample] = True\n",
    "\n",
    "    return links,X_dangxet,X_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gmean(y_test,y_pred):\n",
    "    cm_WSVM = metrics.confusion_matrix(y_test, y_pred)\n",
    "    sensitivity = cm_WSVM[1,1]/(cm_WSVM[1,0]+cm_WSVM[1,1])\n",
    "    specificity = cm_WSVM[0,0]/(cm_WSVM[0,0]+cm_WSVM[0,1])\n",
    "    gmean = math.sqrt(sensitivity*specificity)\n",
    "    return specificity,sensitivity,gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr(X_train,y_test,test_pred,se,sp,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    print(\"So luong samples: \",len(X_train))\n",
    "    print(\"\\n\",classification_report(y_test, test_pred))\n",
    "    print(\"SP      : \",sp)\n",
    "    print(\"SE      : \",se)\n",
    "    print(\"Gmean   : \",gmean)\n",
    "    print(\"F1 Score: \",f1_score(y_test, test_pred))\n",
    "    print(\"Accuracy: \",accuracy_score(y_test,test_pred))\n",
    "    print(\"AUC     : \",roc_auc_score(y_test, test_pred))\n",
    "    print(\"Ma tran nham lan: \\n\",confusion_matrix(y_test, test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr_text(f,X_train,y_test,test_pred,sp,se,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    f.write(f\"\\n\\nSo luong samples Tong: {len(X_train)+len(y_test)}\")\n",
    "    f.write(f\"\\n\\nSo luong samples training: {len(X_train)}\")\n",
    "    f.write(f\"\\nSo luong samples testing: {len(y_test)}\\n\")\n",
    "    f.write(\"\\n\"+str(classification_report(y_test, test_pred)))\n",
    "    f.write(f\"\\nSP      : {sp:0.4f}\")\n",
    "    f.write(f\"\\nSE      : {se:0.4f}\")\n",
    "    f.write(f\"\\nGmean   : {gmean:0.4f}\")\n",
    "    f.write(f\"\\nF1 Score: {f1_score(y_test, test_pred):0.4f}\")\n",
    "    f.write(f\"\\nAccuracy: {accuracy_score(y_test,test_pred):0.4f}\")\n",
    "    f.write(f\"\\nAUC     : {roc_auc_score(y_test, test_pred):0.4f}\")\n",
    "    f.write(\"\\n\\nMa tran nham lan: \\n\"+str(confusion_matrix(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(X, y,name_method =\"actual_hyper_lin\", name_function = \"exp\", beta = None,C = None, gamma = None, u = None, sigma = None):\n",
    "    method = fuzzy.method()\n",
    "    function = fuzzy.function()\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    try:\n",
    "        if name_method == \"own_class_center\": \n",
    "            d = method.own_class_center(X, y)\n",
    "        elif name_method == \"estimated_hyper_lin\": # actual_hyper_lin, own_class_center\n",
    "            d = method.estimated_hyper_lin(X, y)\n",
    "        elif name_method == \"own_class_center_opposite\":\n",
    "            d = method.own_class_center_opposite(X, y)\n",
    "        elif name_method == 'actual_hyper_lin':\n",
    "            d = method.actual_hyper_lin(X, y,C = C, gamma = gamma)\n",
    "        elif name_method == 'own_class_center_divided':\n",
    "            d = method.own_class_center_divided(X, y)\n",
    "        elif name_method == \"distance_center_own_opposite_tam\":\n",
    "            d_own, d_opp, d_tam = method.distance_center_own_opposite_tam(X,y)\n",
    "        else:\n",
    "            print('dont exist method')\n",
    "        \n",
    "        if name_function == \"lin\":\n",
    "            W = function.lin(d)\n",
    "        elif name_function == \"exp\":\n",
    "            W = function.exp(d, beta)\n",
    "        elif name_function == \"lin_center_own\":\n",
    "            W = function.lin_center_own(d, pos_index,neg_index)\n",
    "        elif name_function == 'gau':\n",
    "            W = function.gau(d, u, sigma)\n",
    "        elif name_function == \"func_own_opp_new\":\n",
    "            W = function.func_own_opp_new(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "    except Exception as e:\n",
    "        print('dont exist function')\n",
    "        print(e)\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    r_pos = 1\n",
    "    r_neg = len(pos_index)/len(neg_index)\n",
    "    m = []\n",
    "    W = np.array(W)\n",
    "    m = W[pos_index]*r_pos\n",
    "    m = np.append(m, W[neg_index]*r_neg)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction):\n",
    "    if namemethod ==\"own_class_center_opposite\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_center)\n",
    "        f.write(f\"\\n\\t Beta 'own_class_center_opposite' with exp = {beta_center}\\n\")\n",
    "    elif namemethod ==\"own_class_center\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "        f.write(f\"\\n\\t Beta 'own_class_center' with exp = {beta_center}\\n\")\n",
    "    elif namemethod ==\"own_class_center_divided\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "        f.write(f\"\\n\\t Beta 'own_class_center_divided' with exp = {beta_center}\\n\")\n",
    "    elif namemethod ==\"estimated_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "        f.write(f\"\\n\\t Beta 'estimated_hyper_lin' with exp = {beta_estimate}\\n\")\n",
    "    elif namemethod ==\"actual_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_actual)\n",
    "        f.write(f\"\\n\\t Beta 'actual_hyper_lin' with exp = {beta_actual}\\n\")\n",
    "    else:   \n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction)\n",
    "    return distribution_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5], dtype=int64),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([5,6,7,8,9,10])\n",
    "a = np.where(y>5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tomelinks(f,C,weight,X_test,y_test,X_train,y_train,n_neighbors,clf=None,namemethod=None,namefunction=None):\n",
    "    links,xdx,xtl = is_tomek(X_train,y_train,class_type=[-1.0])\n",
    "    new_W = weight\n",
    "    pos_index = np.where(y_train == 1)[0]\n",
    "    neg_index = np.where(y_train == -1)[0]\n",
    "    clf = Wsvm(C,weight)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    specificity,sensitivity,gmean = Gmean(y_test,y_predict)\n",
    "    nn2 = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn2.fit(X_train)\n",
    "    y_nn = []\n",
    "    neg_pred = clf.predict(X_train[neg_index])\n",
    "    idx_neg_wrong = np.where(neg_pred != -1.0)\n",
    "    \n",
    "    new_W[idx_neg_wrong] = 0\n",
    "\n",
    "    for ind,i in enumerate(xdx):\n",
    "        y_pred = clf.predict([X_train[i]])  #\n",
    "        if y_pred == -1.0:                          \n",
    "            knn_X = (nn2.kneighbors([X_train[i]])[1]).tolist() \n",
    "            for j in knn_X[0]:\n",
    "                y_nn.append(y_train[j])    # gom nhãn láng giềng của X_train[i] bị dự đoán sai vào y_nn\n",
    "        else:\n",
    "            new_W[xtl[ind]] = new_W[xtl[ind]]/2\n",
    "            new_W[i] = new_W[i]*1.25\n",
    "\n",
    "    y_nn = np.array(y_nn)\n",
    "    if len(y_nn)>0:\n",
    "        y_nn = np.array_split(y_nn, len(y_nn)/n_neighbors)\n",
    "    for ind,i in enumerate(range(0,len(y_nn))):      #\n",
    "        if 1 not in y_nn[i][1:]:      # Nếu không có nhãn 1 xung quanh X_train[i] bị dự đoán sai => xóa X_train[i]\n",
    "            new_W[xdx[ind]] = 0\n",
    "        else:\n",
    "            new_W[xtl[ind]] = new_W[xtl[ind]]/2\n",
    "            new_W[xdx[ind]] = new_W[xdx[ind]]*1.25\n",
    "\n",
    "    return new_W,gmean,sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfb(f,C,weight,namemethod,namefunction,T,X_test,y_test,X_train,y_train,n_neighbors,thamso1,thamso2): #loop find the best\n",
    "    gmax = 0\n",
    "    tmax = 0\n",
    "    semax = 0\n",
    "    t_semax = 0\n",
    "    for i in range(0,T):\n",
    "        f.write(f\"\\t\\t Vong Lap thu: T = {i+1}\")\n",
    "        f.write(f\"\\n===================================================================================================================\")\n",
    "        f.write(f\"\\n\\n\\tFuzzy SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "        weight, gmeanfirst, SEfirst = data_tomelinks(f,C,weight,X_test,y_test,X_train,y_train,n_neighbors,clf=None,namemethod=namemethod,namefunction=namefunction)\n",
    "        #distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "        clf = Wsvm(C,weight)\n",
    "        #print(X_train)\n",
    "        #print(y_train)\n",
    "        clf.fit(X_train, y_train)\n",
    "        #print(clf.predict([X_test_val[5]]))\n",
    "        pred2 = clf.predict(X_test)    #X_val\n",
    "        sp,se,gmean = Gmean(y_test,pred2) #y_val\n",
    "\n",
    "        pred_all = clf.predict(X_test)    #X_val\n",
    "        sp_all,se_all,gmean_all = Gmean(y_test,pred_all)\n",
    "\n",
    "        if(gmeanfirst > gmax):\n",
    "            gmax = gmeanfirst\n",
    "            tmax = i+100\n",
    "        if (gmean_all > gmax):\n",
    "            gmax = gmean_all\n",
    "            tmax = i\n",
    "        if (SEfirst > semax):\n",
    "            semax = SEfirst\n",
    "            t_semax = i+100\n",
    "        if (se_all > semax):\n",
    "            semax = se_all\n",
    "            t_semax = i   \n",
    "        #metr(X_train,y_test_val,pred2,sp,se,gmean)\n",
    "        f.write(f\"\\n\\n\\t****** Danh gia tren tap Validation:\\n\")\n",
    "        metr_text(f,X_train,y_test,pred2,sp,se,gmean)\n",
    "        f.write(f\"\\n\\n\\t****** Danh gia tren tap Test:\\n\")\n",
    "        metr_text(f,X_train,y_test,pred_all,sp_all,se_all,gmean_all)\n",
    "        # if ((gmeanfirst - gmean) <= thamso1) or (gmeanfirst > thamso2):\n",
    "        #     f.write(\"\\n_____Gmean_ERROR!!!____\\n\")\n",
    "        #     print(\"\\n_____Gmean_ERROR!!!____\\n\")\n",
    "        #     return X_train, y_train\n",
    "        # else:\n",
    "        #     gmean = gmeanfirst\n",
    "        f.write(f\"\\n===================================================================================================================\\n\")\n",
    "    f.write(f\"\\nFuzzy SVM name_method = '{namemethod}',name_function = '{namefunction}'\")\n",
    "    f.write(f\"\\n*** T = {tmax}; K = {n_neighbors}; GmeanMax = {gmax:0.4f}\\n\")\n",
    "    f.write(f\"\\n*** T = {t_semax}; K = {n_neighbors}; SeMax = {semax:0.4f}\\n\")\n",
    "    f.write(f\"\\n===================================================================================================================\\n\")\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "W.SVM starting...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\FullCode_AdjustW_CopyKFold.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000013?line=89'>90</a>\u001b[0m N, d \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mshape\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000013?line=90'>91</a>\u001b[0m distribution_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(N)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000013?line=91'>92</a>\u001b[0m test_pred \u001b[39m=\u001b[39m wsvm(C,X_train, y_train, X_test, distribution_weight)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000013?line=92'>93</a>\u001b[0m sp,se,gmean \u001b[39m=\u001b[39m Gmean(y_test,test_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000013?line=93'>94</a>\u001b[0m \u001b[39m#metr(X_train,y_test,test_pred,sp,se,gmean)\u001b[39;00m\n",
      "\u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\FullCode_AdjustW_CopyKFold.ipynb Cell 3'\u001b[0m in \u001b[0;36mwsvm\u001b[1;34m(C, X_train, y_train, X_test, distribution_weight)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwsvm\u001b[39m(C,X_train, y_train,X_test,distribution_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000002?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m Wsvm(C,distribution_weight)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000002?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000002?line=3'>4</a>\u001b[0m     test_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_CopyKFold.ipynb#ch0000002?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m test_pred\n",
      "File \u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\wsvm\\application.py:22\u001b[0m, in \u001b[0;36mWsvm.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/application.py?line=19'>20</a>\u001b[0m P, q, G, h, A, b \u001b[39m=\u001b[39m methods\u001b[39m.\u001b[39mdual_problem_quadratic_program(X, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_weight)\n\u001b[0;32m     <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/application.py?line=20'>21</a>\u001b[0m \u001b[39m#Solve Quadratic Program\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/application.py?line=21'>22</a>\u001b[0m sol \u001b[39m=\u001b[39m methods\u001b[39m.\u001b[39;49mdual_problem_quadratic_solver(P, q,G, h, A, b)\n\u001b[0;32m     <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/application.py?line=23'>24</a>\u001b[0m \u001b[39m# Caculate Lagrange \u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/application.py?line=24'>25</a>\u001b[0m lam \u001b[39m=\u001b[39m methods\u001b[39m.\u001b[39msvm_lagrange_mutipliers(sol)\n",
      "File \u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\wsvm\\methods.py:56\u001b[0m, in \u001b[0;36mdual_problem_quadratic_solver\u001b[1;34m(P, q, G, h, A, b)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/methods.py?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdual_problem_quadratic_solver\u001b[39m(P, q, G, h, A, b):\n\u001b[0;32m     <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/methods.py?line=54'>55</a>\u001b[0m     solvers\u001b[39m.\u001b[39moptions[\u001b[39m'\u001b[39m\u001b[39mshow_progress\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/wsvm/methods.py?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m solvers\u001b[39m.\u001b[39;49mqp(P, q, G, h, A, b)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\coneprog.py:4485\u001b[0m, in \u001b[0;36mqp\u001b[1;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4474'>4475</a>\u001b[0m         pinfres, dinfres \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4476'>4477</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: status, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: x, \u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m: s, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m: y, \u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m: z,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4477'>4478</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprimal objective\u001b[39m\u001b[39m'\u001b[39m: pcost, \u001b[39m'\u001b[39m\u001b[39mdual objective\u001b[39m\u001b[39m'\u001b[39m: dcost,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4478'>4479</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mgap\u001b[39m\u001b[39m'\u001b[39m: gap, \u001b[39m'\u001b[39m\u001b[39mrelative gap\u001b[39m\u001b[39m'\u001b[39m: relgap,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4481'>4482</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresidual as primal infeasibility certificate\u001b[39m\u001b[39m'\u001b[39m: pinfres,\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4482'>4483</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresidual as dual infeasibility certificate\u001b[39m\u001b[39m'\u001b[39m: dinfres}\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=4484'>4485</a>\u001b[0m \u001b[39mreturn\u001b[39;00m coneqp(P, q, G, h, \u001b[39mNone\u001b[39;49;00m, A,  b, initvals, kktsolver \u001b[39m=\u001b[39;49m kktsolver, options \u001b[39m=\u001b[39;49m options)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\coneprog.py:2256\u001b[0m, in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2243'>2244</a>\u001b[0m misc\u001b[39m.\u001b[39mssqr(lmbdasq, lmbda, dims)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2246'>2247</a>\u001b[0m \u001b[39m# f3(x, y, z) solves\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2247'>2248</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2248'>2249</a>\u001b[0m \u001b[39m#    [ P   A'  G'    ] [ ux        ]   [ bx ]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2252'>2253</a>\u001b[0m \u001b[39m# On entry, x, y, z containg bx, by, bz.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2253'>2254</a>\u001b[0m \u001b[39m# On exit, they contain ux, uy, uz.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2255'>2256</a>\u001b[0m \u001b[39mtry\u001b[39;00m: f3 \u001b[39m=\u001b[39m kktsolver(W)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2256'>2257</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mArithmeticError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=2257'>2258</a>\u001b[0m     \u001b[39mif\u001b[39;00m iters \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\coneprog.py:1981\u001b[0m, in \u001b[0;36mconeqp.<locals>.kktsolver\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=1979'>1980</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkktsolver\u001b[39m(W):\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/coneprog.py?line=1980'>1981</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m factor(W, P)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\misc.py:1452\u001b[0m, in \u001b[0;36mkkt_chol2.<locals>.factor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/misc.py?line=1449'>1450</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/misc.py?line=1450'>1451</a>\u001b[0m     base\u001b[39m.\u001b[39msyrk(F[\u001b[39m'\u001b[39m\u001b[39mGs\u001b[39m\u001b[39m'\u001b[39m], F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m], trans \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m, partial \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/misc.py?line=1451'>1452</a>\u001b[0m     \u001b[39mif\u001b[39;00m mnl: base\u001b[39m.\u001b[39msyrk(F[\u001b[39m'\u001b[39m\u001b[39mDfs\u001b[39m\u001b[39m'\u001b[39m], F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m], trans \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m, beta \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m, \n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/misc.py?line=1452'>1453</a>\u001b[0m         partial \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/misc.py?line=1453'>1454</a>\u001b[0m     \u001b[39mif\u001b[39;00m H \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Anaconda/envs/FSVM-CIL/lib/site-packages/cvxopt/misc.py?line=1454'>1455</a>\u001b[0m         F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m H\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C = 100\n",
    "thamso1 = 1\n",
    "thamso2 = 1\n",
    "T = 1\n",
    "n_neighbor = 5\n",
    "test_size = [0.2,0.3,0.4]\n",
    "testsize_val = 0.2\n",
    "K_big = 5\n",
    "K_small = 5\n",
    "# data = [Co_Author, Abanole, Ecoli, Ecloli1, Ecoli3, Glass1, Glass4, Haberman, Waveform, New_thyroid2, Page_blocks,\n",
    "#             Pima_Indians_Diabetes, Satimage, Transfusion, Yeast]\n",
    "data = [Transfution_Kfold]\n",
    "\n",
    "# !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!!\n",
    "beta_center, beta_estimate, beta_actual = 0.5, 0.8, 1 # !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!!\n",
    "# !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!\n",
    "\n",
    "name_method =[\"own_class_center\",\"estimated_hyper_lin\",\"actual_hyper_lin\",\"distance_center_own_opposite_tam\"]\n",
    "#name_method =[\"own_class_center_divided\"]\n",
    "name_function = [\"lin_center_own\",\"exp\",\"func_own_opp_new\",\"lin\"]\n",
    "\n",
    "time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "filepath = \"./text_script\"\n",
    "\n",
    "#svc lib\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "#svm scratch\n",
    "svm_scr = Svm(C)\n",
    "#W.svm\n",
    "\n",
    "for dataset in data:\n",
    "    filename = (str(dataset).split(\"\\\\\")[-1]).split(\".\")[0]\n",
    "    f = open(f\"{filepath}/Data_{filename}_{time}_Detail.txt\", \"w\")\n",
    "    f.write(f\"\\nC = {C}, thamso1 = {thamso1}, thamso2 = {thamso2}, T = {T}, n_neighbors = {n_neighbor}  \\n\")\n",
    "    f.write(f\"\\n\\n\\tUSING DATASET : {filename}\\n\")\n",
    "\n",
    "    f2 = open(f\"{filepath}/Data_{filename}_{time}_Main.txt\", \"w\")\n",
    "    f2.write(f\"\\nC = {C}, thamso1 = {thamso1}, thamso2 = {thamso2}, T = {T}, n_neighbors = {n_neighbor}  \\n\")\n",
    "    f2.write(f\"\\n\\n\\tUSING DATASET : {filename}\\n\")\n",
    "    \n",
    "\n",
    "    #print(f\"\\n\\tUSING DATASET : {filename}\\n\")\n",
    "    # for testsize in test_size:\n",
    "    #     X_train, y_train, X_test, y_test = dataset.load_data(test_size=testsize)\n",
    "    X, y = dataset.load_data()\n",
    "    kfold_validation = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for train_index, test_index in kfold_validation.split(X,y):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        #Scalling Data\n",
    "        sc_X = StandardScaler()\n",
    "        X_train = sc_X.fit_transform(X_train)\n",
    "        X_test = sc_X.transform(X_test)\n",
    "        y_train = np.array(y_train)\n",
    "        print(type(X_train), type(y_train))\n",
    "\n",
    "        #print(f\"\\t======== TestSize: {testsize} ========\")\n",
    "        #print(\"So luong sample nguyen ban ban dau: \",len(X_train)+len(X_test_val)+len(X_test))\n",
    "\n",
    "        # f.write(f\"\\n\\n\\t======== TestSize: {testsize} ========\\n\\n\")\n",
    "        f.write(\"\\n\\n\\t====== NOT USING TOMEKLINKS ========== \\n\")\n",
    "\n",
    "        # f2.write(f\"\\n\\n\\t======== TestSize: {testsize} ========\\n\\n\")\n",
    "        f2.write(\"\\n\\n\\t====== NOT USING TOMEKLINKS ========== \\n\")\n",
    "\n",
    "        #Svm library\n",
    "        f.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "        f2.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "        #print(\"SVM LIBRARY starting...\\n\")\n",
    "        test_pred = svm_lib(X_train, y_train,X_test)\n",
    "        sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        #metr(X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        # #Svm scratch\n",
    "        # f.write(\"\\n\\n\\tSVM starting...\\n\")\n",
    "        # f2.write(\"\\n\\n\\tSVM starting...\\n\")\n",
    "        # print(\"SVM starting...\\n\")\n",
    "        # test_pred = svm(C,X_train, y_train,X_test)\n",
    "        # sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        # #metr(X_train,y_test,test_pred,sp,se,gmean)\n",
    "        # metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        # metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        #Wsvm\n",
    "        f.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "        f2.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "        print(\"W.SVM starting...\\n\")\n",
    "        N, d = X_train.shape\n",
    "        distribution_weight = np.ones(N)\n",
    "        test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "        sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        #metr(X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        #FuzyyWsvm\n",
    "        for namemethod in name_method:\n",
    "            for namefunction in name_function:\n",
    "                if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "                    continue\n",
    "                elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "                    continue\n",
    "                elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"distance_center_own_opposite_tam\" and namefunction == \"lin\":\n",
    "                    continue\n",
    "                elif namemethod == \"own_class_center\" and namefunction == \"lin\":\n",
    "                    continue\n",
    "                elif namemethod == \"estimated_hyper_lin\" and namefunction == \"lin\":\n",
    "                    continue\n",
    "                elif namemethod == \"actual_hyper_lin\" and namefunction == \"lin_center_own\":\n",
    "                    continue\n",
    "                else:\n",
    "                    f.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    f2.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                    __ = fuzzy_weight(f2,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                    test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "                    sp,se,gmean = Gmean(y_test,test_pred)\n",
    "                    metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "                    metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        # f.write(f\"\\n\\n\\t======== TestSize: {testsize} ========\\n\\n\")\n",
    "        f.write(\"\\n\\n\\t====== USING TOMEKLINKS ========== \\n\")\n",
    "\n",
    "        # f2.write(f\"\\n\\n\\t======== TestSize: {testsize} ========\\n\\n\")\n",
    "        f2.write(\"\\n\\n\\t====== USING TOMEKLINKS ========== \\n\")\n",
    "\n",
    "        # #Svm library\n",
    "        # f.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "        # f2.write(\"\\n\\n\\tSVM LIBRARY starting...\\n\")\n",
    "        # #print(\"SVM LIBRARY starting...\\n\")\n",
    "        # test_pred = svm_lib(X_train, y_train,X_test)\n",
    "        # sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        # #metr(X_train,y_test,test_pred,sp,se,gmean)\n",
    "        # metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        # metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "        \n",
    "        # #Wsvm\n",
    "        # f.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "        # f2.write(\"\\n\\n\\tW.SVM starting...\\n\")\n",
    "        # print(\"W.SVM starting...\\n\")\n",
    "        # N, d = X_train.shape\n",
    "        # distribution_weight = np.ones(N)\n",
    "        # test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "        # sp,se,gmean = Gmean(y_test,test_pred)\n",
    "        # #metr(X_train,y_test,test_pred,sp,se,gmean)\n",
    "        # metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "        # metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "\n",
    "        #FuzyyWsvm\n",
    "        for namemethod in name_method:\n",
    "            for namefunction in name_function:\n",
    "                if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "                    continue\n",
    "                elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "                    continue\n",
    "                elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                    continue\n",
    "                elif namemethod == \"distance_center_own_opposite_tam\" and namefunction == \"lin\":\n",
    "                    continue\n",
    "                elif namemethod == \"own_class_center\" and namefunction == \"lin\":\n",
    "                    continue\n",
    "                elif namemethod == \"estimated_hyper_lin\" and namefunction == \"lin\":\n",
    "                    continue\n",
    "                elif namemethod == \"actual_hyper_lin\" and namefunction == \"lin_center_own\":\n",
    "                    continue\n",
    "                else:\n",
    "                    f.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    f2.write(f\"\\n\\n\\tFuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                    distribution_weight = fuzzy_weight(f,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                    __ = fuzzy_weight(f2,beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                    new_W = lfb(f,C,distribution_weight,namemethod,namefunction,T,X_test,y_test,X_train,y_train,n_neighbor,thamso1,thamso2)\n",
    "                    test_pred = wsvm(C,X_train, y_train, X_test, new_W)\n",
    "                    sp,se,gmean = Gmean(y_test,test_pred)\n",
    "\n",
    "                    #metr(X_train,y_test,test_pred,sp,se,gmean)\n",
    "                    metr_text(f,X_train,y_test,test_pred,sp,se,gmean)\n",
    "                    metr_text(f2,X_train,y_test,test_pred,sp,se,gmean)\n",
    "\n",
    "    f.write(\"\\n===================================================================================\\n\")\n",
    "    f.close()\n",
    "    f2.write(\"\\n===================================================================================\\n\")\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()\n",
    "f2.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3eb084ff34f185e711904a41a1d2fc9cd89e03d041f4053257b7f71ab3d6f28c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('FSVM-CIL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
