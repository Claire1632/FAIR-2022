{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data import Vertebral_column, indian_liver_patient\n",
    "from Processing_Data import Haberman\n",
    "from Processing_Data import Waveform\n",
    "from Processing_Data import New_thyroid2\n",
    "from Processing_Data import Page_blocks\n",
    "from Processing_Data import Pima_Indians_Diabetes, Pima\n",
    "from Processing_Data import Satimage\n",
    "from Processing_Data import Transfusion, Transfution_Kfold\n",
    "from Processing_Data import Yeast, Yeast_KFold, Waveform_KFold, Satimage_KFold\n",
    "from wsvm.application import Wsvm\n",
    "from svm.application import Svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics  import classification_report,precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from fuzzy.weight import fuzzy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Processing_Data import Ecoli_Kfold\n",
    "from Processing_Data import Haberman_KFold\n",
    "import csv\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Max(arr):\n",
    "    \"\"\"\n",
    "    :param arr: list of integer\n",
    "    :return: item max of list\n",
    "    \"\"\"\n",
    "    max = arr[0]\n",
    "\n",
    "    for i in range(len(arr)):\n",
    "        if max < arr[i]:\n",
    "            max = arr[i]\n",
    "\n",
    "    return max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624695048\n",
      "0.622459995\n",
      "0.624695048\n",
      "0.624695048\n",
      "0.624695048\n",
      "0.624695048\n",
      "0.624695048\n",
      "0.624695048\n",
      "0.624695048\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n",
      "0.626922131\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/ADMIN/OneDrive/Desktop/KQTN-2010/Data_Yeast_KFold_19102022_204220_Full.csv')\n",
    "for i in range(len(df)):\n",
    "    if (df['Time'][i] == 1 and df['Fold'][i] == 1 and df['T'][i] != 0):\n",
    "        if (df['Name Method'][i] == 'own_class_center' and df['Name Function'][i] == 'lin_center_own'):\n",
    "            print(df['Gmean'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_lib(X_train, y_train,X_test):\n",
    "    svc=SVC(probability=True, kernel='linear')\n",
    "    model = svc.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsvm(C,X_train, y_train,X_test,distribution_weight=None):\n",
    "    model = Wsvm(C,distribution_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(C,X_train, y_train,X_test):\n",
    "    model = Svm(C)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tomek_new(X,y, class_type):\n",
    "    print(y)\n",
    "    print(type(y))\n",
    "    nn = NearestNeighbors(n_neighbors=2)\n",
    "    nn.fit(X)\n",
    "    nn_index = nn.kneighbors(X, return_distance=False)[:, 1] #Trả về một mảng gồm chỉ số của các điểm gần nhất của mỗi mẫu tương ứng\n",
    "    links = np.zeros(len(y), dtype=bool)\n",
    "    # find which class to not consider\n",
    "    class_excluded = [c for c in np.unique(y) if c not in class_type] #[1.0]\n",
    "    X_dangxet = []\n",
    "    X_tl = []\n",
    "    # there is a Tomek link between two samples if they are both nearest\n",
    "    # neighbors of each others.\n",
    "    for index_sample, target_sample in enumerate(y):\n",
    "        if target_sample in class_excluded:\n",
    "            continue\n",
    "        if y[nn_index[index_sample]] != target_sample: #target_sample=[-1.0]; Kiểm tra nhãn của những điểm gần nhất trong mảng nn_index (điểm được xét và điểm gần nhất phải khác nhãn)\n",
    "            if nn_index[nn_index[index_sample]] == index_sample:\n",
    "                X_tl.append(index_sample) #X_tl: mảng chứa chỉ số của những mẫu âm trong các cặp TL\n",
    "                X_dangxet.append(nn_index[index_sample]) #X_dangxet: mảng chứa chỉ số của những mẫu dương trong các cặp TL\n",
    "                links[index_sample] = True #Cập nhật trạng thái của các mẫu âm trong cặp TL\n",
    "\n",
    "    stt = np.zeros(len(X_dangxet), dtype=int)\n",
    "    arr_tlp = np.stack((X_dangxet, X_tl, stt), axis=1)\n",
    "\n",
    "    return arr_tlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gmean(y_test,y_pred):\n",
    "    cm_WSVM = metrics.confusion_matrix(y_test, y_pred)\n",
    "    sensitivity = cm_WSVM[1,1]/(cm_WSVM[1,0]+cm_WSVM[1,1])\n",
    "    specificity = cm_WSVM[0,0]/(cm_WSVM[0,0]+cm_WSVM[0,1])\n",
    "    gmean = math.sqrt(sensitivity*specificity)\n",
    "    return specificity,sensitivity,gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr(X_train,y_test,test_pred,se,sp,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    print(\"So luong samples: \",len(X_train))\n",
    "    print(\"\\n\",classification_report(y_test, test_pred))\n",
    "    print(\"SP      : \",sp)\n",
    "    print(\"SE      : \",se)\n",
    "    print(\"Gmean   : \",gmean)\n",
    "    print(\"F1 Score: \",f1_score(y_test, test_pred))\n",
    "    print(\"Accuracy: \",accuracy_score(y_test,test_pred))\n",
    "    print(\"AUC     : \",roc_auc_score(y_test, test_pred))\n",
    "    print(\"Ma tran nham lan: \\n\",confusion_matrix(y_test, test_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr_text(f,X_train,y_test,test_pred,sp,se,gmean):\n",
    "    #se,sp,gmean = Gmean(y_test,test_pred)\n",
    "    f.write(f\"\\n\\nSo luong samples Tong: {len(X_train)+len(y_test)}\")\n",
    "    f.write(f\"\\n\\nSo luong samples training: {len(X_train)}\")\n",
    "    f.write(f\"\\nSo luong samples testing: {len(y_test)}\\n\")\n",
    "    f.write(\"\\n\"+str(classification_report(y_test, test_pred)))\n",
    "    f.write(f\"\\nSP      : {sp:0.4f}\")\n",
    "    f.write(f\"\\nSE      : {se:0.4f}\")\n",
    "    f.write(f\"\\nGmean   : {gmean:0.4f}\")\n",
    "    f.write(f\"\\nF1 Score: {f1_score(y_test, test_pred):0.4f}\")\n",
    "    f.write(f\"\\nAccuracy: {accuracy_score(y_test,test_pred):0.4f}\")\n",
    "    f.write(f\"\\nAUC     : {roc_auc_score(y_test, test_pred):0.4f}\")\n",
    "    f.write(\"\\n\\nMa tran nham lan: \\n\"+str(confusion_matrix(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(X, y,name_method =\"actual_hyper_lin\", name_function = \"exp\", beta = None,C = None, gamma = None, u = None, sigma = None):\n",
    "    method = fuzzy.method()\n",
    "    function = fuzzy.function()\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    try:\n",
    "        if name_method == \"own_class_center\": \n",
    "            d = method.own_class_center(X, y)\n",
    "        elif name_method == \"estimated_hyper_lin\": # actual_hyper_lin, own_class_center\n",
    "            d = method.estimated_hyper_lin(X, y)\n",
    "        elif name_method == \"own_class_center_opposite\":\n",
    "            d = method.own_class_center_opposite(X, y)\n",
    "        elif name_method == 'actual_hyper_lin':\n",
    "            d = method.actual_hyper_lin(X, y,C = C, gamma = gamma)\n",
    "        elif name_method == 'own_class_center_divided':\n",
    "            d = method.own_class_center_divided(X, y)\n",
    "        elif name_method == \"distance_center_own_opposite_tam\":\n",
    "            d_own, d_opp, d_tam = method.distance_center_own_opposite_tam(X,y)\n",
    "        else:\n",
    "            print('dont exist method')\n",
    "        \n",
    "        if name_function == \"lin\":\n",
    "            W = function.lin(d)\n",
    "        elif name_function == \"exp\":\n",
    "            W = function.exp(d, beta)\n",
    "        elif name_function == \"lin_center_own\":\n",
    "            W = function.lin_center_own(d, pos_index,neg_index)\n",
    "        elif name_function == 'gau':\n",
    "            W = function.gau(d, u, sigma)\n",
    "        elif name_function == \"func_own_opp_new\":\n",
    "            W = function.func_own_opp_new(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "        elif name_function == \"func_own_opp_new_v1\":\n",
    "            W = function.func_own_opp_new_v1(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "        elif name_function == \"func_own_opp_new_v2\":\n",
    "            W = function.func_own_opp_new_v2(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "    except Exception as e:\n",
    "        print('dont exist function')\n",
    "        print(e)\n",
    "    # pos_index = np.where(y == 1)[0]\n",
    "    # neg_index = np.where(y == -1)[0]\n",
    "    r_pos = 1\n",
    "    r_neg = len(pos_index)/len(neg_index)\n",
    "    m = []\n",
    "    W = np.array(W)\n",
    "    m = W[pos_index]*r_pos\n",
    "    m = np.append(m, W[neg_index]*r_neg)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction):\n",
    "    if namemethod ==\"own_class_center_opposite\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_center)\n",
    "    elif namemethod ==\"own_class_center\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "    elif namemethod ==\"own_class_center_divided\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "    elif namemethod ==\"estimated_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "    elif namemethod ==\"actual_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_actual)\n",
    "    else:   \n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction)\n",
    "    return distribution_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tomelinks_final(C,weight,X_test,y_test,X_train,y_train,n_neighbors,arr_tlp,clf=None,namemethod=None,namefunction=None):\n",
    "    ro1 = 0.1\n",
    "    ro3 = 0.1\n",
    "    ro4 = 0.5\n",
    "    ro2 = 0.5\n",
    "    \n",
    "    new_W = weight\n",
    "    pos_index = np.where(y_train == 1)[0]\n",
    "    neg_index = np.where(y_train == -1)[0]\n",
    "    clf = Wsvm(C,new_W)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # y_predict = clf.predict(X_test)\n",
    "    # specificity,sensitivity,gmean = Gmean(y_test,y_predict)\n",
    "    nn2 = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn2.fit(X_train)\n",
    "\n",
    "    # # Mẫu âm bị phân loại sai -> Giảm trọng số của mẫu âm đó\n",
    "    # neg_pred = clf.predict(X_train[neg_index])\n",
    "    # idx_neg_wrong = np.where(neg_pred != -1.0)\n",
    "    # new_W[idx_neg_wrong] =  new_W[idx_neg_wrong]*0.5 # giam manh (Co-Author*0.9)\n",
    "\n",
    "    # Tăng, giảm trọng số của các mẫu trong TLPs\n",
    "    # Trường hợp 1, 2, 3, 4\n",
    "    ind_nn_pos = [] # chứa chỉ số của các mẫu dương bị phân loại sai trong ind_posX\n",
    "    y_nn_pos = [] # chứa nhãn của k mẫu dữ liệu gần nhất với mẫu dương được xét\n",
    "    ind_nn_neg = [] # chứa chỉ số của các mẫu âm bị phân loại sai trong ind_negX\n",
    "    y_nn_neg = [] # chứa nhãn của k mẫu dữ liệu gần nhất với mẫu âm được xét\n",
    "\n",
    "    for ind,i in enumerate(arr_tlp):\n",
    "        y_pred_pos = clf.predict([X_train[i[0]]]) #positive\n",
    "        y_pred_neg = clf.predict([X_train[i[1]]]) #negative\n",
    "        if (y_pred_pos == 1) and (y_pred_neg == 1): #dương được dự đoán đúng & âm bị dự đoán sai (TH1)\n",
    "            new_W[i[0]] = new_W[i[0]]*(1 + ro1) \n",
    "            new_W[i[1]] = new_W[i[1]]*(1 - ro1)\n",
    "            i[2] = 1\n",
    "\n",
    "            ind_nn_neg.append(ind)                          \n",
    "            knn_X = (nn2.kneighbors([X_train[i[1]]])[1]).tolist()  \n",
    "            for j in knn_X[0]:\n",
    "                y_nn_neg.append(y_train[j])   # gom nhãn láng giềng của X_train[i] bị dự đoán sai vào y_nn_neg\n",
    "\n",
    "        if (y_pred_pos == -1) and (y_pred_neg == -1): #âm được dự đoán đúng & dương bị dự đoán sai (TH3)\n",
    "            new_W[i[0]] = new_W[i[0]]*(1 + ro3) \n",
    "            new_W[i[1]] = new_W[i[1]]*(1 - ro3)\n",
    "            i[2] = 3\n",
    "\n",
    "            ind_nn_pos.append(ind)                          \n",
    "            knn_X = (nn2.kneighbors([X_train[i[0]]])[1]).tolist()  \n",
    "            for j in knn_X[0]:\n",
    "                y_nn_pos.append(y_train[j])   # gom nhãn láng giềng của X_train[i] bị dự đoán sai vào y_nn_pos\n",
    "\n",
    "    ind_nn_neg = np.array(ind_nn_neg)\n",
    "    y_nn_neg = np.array(y_nn_neg)\n",
    "    if len(y_nn_neg)>0: #(TH2)\n",
    "        y_nn_neg = np.array_split(y_nn_neg, len(y_nn_neg)/n_neighbors) \n",
    "        for ind1,id1 in enumerate(ind_nn_neg): \n",
    "            if -1 not in y_nn_neg[ind1][1:]:      # Nếu không có nhãn -1 xung quanh X_train[i] bị dự đoán sai => nhiễu âm -> giảm mạnh trọng số\n",
    "                for a in arr_tlp[[id1]]:\n",
    "                    new_W[a[1]] = new_W[a[1]]*ro2\n",
    "                arr_tlp[id1][2] = 2\n",
    "\n",
    "\n",
    "    ind_nn_pos = np.array(ind_nn_pos)\n",
    "    y_nn_pos = np.array(y_nn_pos)\n",
    "    if len(y_nn_pos)>0: #(TH4)\n",
    "        y_nn_pos = np.array_split(y_nn_pos, len(y_nn_pos)/n_neighbors) \n",
    "        for ind2,id2 in enumerate(ind_nn_pos):   \n",
    "            if 1 not in y_nn_pos[ind2][1:]:      # Nếu không có nhãn 1 xung quanh X_train[i] bị dự đoán sai => nhiễu dương -> giảm mạnh trọng số\n",
    "                for a in arr_tlp[[id2]]:\n",
    "                    new_W[a[0]] = new_W[a[0]]*ro4\n",
    "                arr_tlp[id2][2] = 4\n",
    "\n",
    "    return new_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lan boc:  1\n",
      "(336, 7)\n",
      "\n",
      "Fold thu  1\n",
      "(68, 7)\n",
      "SVM LIBRARY starting...\n",
      "\n",
      "W.SVM starting...\n",
      "\n",
      "\n",
      "------------- Using AFW-CIL---------------------\n",
      "\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "<class 'numpy.ndarray'>\n",
      "Fuzzy W.SVM name_method = 'own_class_center',name_function = 'lin_center_own' starting...\n",
      "\n",
      "At T =  1\n",
      "At T =  2\n",
      "At T =  3\n",
      "At T =  4\n",
      "At T =  5\n",
      "Fuzzy W.SVM name_method = 'own_class_center',name_function = 'exp' starting...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\FullCode_AdjustW_KFold_Full_Lite.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m __ \u001b[39m=\u001b[39m fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)                            \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,T):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m     \u001b[39m# new_W = lfb(f,C,distribution_weight,namemethod,namefunction,T,X_test,y_test,X_train,y_train,n_neighbor,thamso1,thamso2)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m     new_W \u001b[39m=\u001b[39m data_tomelinks_final(C,distribution_weight,X_test,y_test,X_train,y_train,n_neighbor,arr_tlp,clf\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,namemethod\u001b[39m=\u001b[39;49mnamemethod,namefunction\u001b[39m=\u001b[39;49mnamefunction)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     test_pred \u001b[39m=\u001b[39m wsvm(C,X_train, y_train, X_test, new_W)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m     sp,se,gmean \u001b[39m=\u001b[39m Gmean(y_test,test_pred)\n",
      "\u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\FullCode_AdjustW_KFold_Full_Lite.ipynb Cell 14\u001b[0m in \u001b[0;36mdata_tomelinks_final\u001b[1;34m(C, weight, X_test, y_test, X_train, y_train, n_neighbors, arr_tlp, clf, namemethod, namefunction)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m neg_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y_train \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m clf \u001b[39m=\u001b[39m Wsvm(C,new_W)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# y_predict = clf.predict(X_test)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# specificity,sensitivity,gmean = Gmean(y_test,y_predict)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MULTIMEDIA/MACHINE_LEARNING_THAY_QUANG/FUZZY%20SVM/CODE/07_04_2022/fuzzy_svm/FullCode_AdjustW_KFold_Full_Lite.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m nn2 \u001b[39m=\u001b[39m NearestNeighbors(n_neighbors\u001b[39m=\u001b[39mn_neighbors)\n",
      "File \u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\wsvm\\application.py:22\u001b[0m, in \u001b[0;36mWsvm.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m P, q, G, h, A, b \u001b[39m=\u001b[39m methods\u001b[39m.\u001b[39mdual_problem_quadratic_program(X, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_weight)\n\u001b[0;32m     21\u001b[0m \u001b[39m#Solve Quadratic Program\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m sol \u001b[39m=\u001b[39m methods\u001b[39m.\u001b[39;49mdual_problem_quadratic_solver(P, q,G, h, A, b)\n\u001b[0;32m     24\u001b[0m \u001b[39m# Caculate Lagrange \u001b[39;00m\n\u001b[0;32m     25\u001b[0m lam \u001b[39m=\u001b[39m methods\u001b[39m.\u001b[39msvm_lagrange_mutipliers(sol)\n",
      "File \u001b[1;32md:\\MULTIMEDIA\\MACHINE_LEARNING_THAY_QUANG\\FUZZY SVM\\CODE\\07_04_2022\\fuzzy_svm\\wsvm\\methods.py:56\u001b[0m, in \u001b[0;36mdual_problem_quadratic_solver\u001b[1;34m(P, q, G, h, A, b)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdual_problem_quadratic_solver\u001b[39m(P, q, G, h, A, b):\n\u001b[0;32m     55\u001b[0m     solvers\u001b[39m.\u001b[39moptions[\u001b[39m'\u001b[39m\u001b[39mshow_progress\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m solvers\u001b[39m.\u001b[39;49mqp(P, q, G, h, A, b)\n",
      "File \u001b[1;32md:\\APP\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\coneprog.py:4485\u001b[0m, in \u001b[0;36mqp\u001b[1;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[0;32m   4475\u001b[0m         pinfres, dinfres \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   4477\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: status, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: x, \u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m: s, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m: y, \u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m: z,\n\u001b[0;32m   4478\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprimal objective\u001b[39m\u001b[39m'\u001b[39m: pcost, \u001b[39m'\u001b[39m\u001b[39mdual objective\u001b[39m\u001b[39m'\u001b[39m: dcost,\n\u001b[0;32m   4479\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mgap\u001b[39m\u001b[39m'\u001b[39m: gap, \u001b[39m'\u001b[39m\u001b[39mrelative gap\u001b[39m\u001b[39m'\u001b[39m: relgap,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4482\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresidual as primal infeasibility certificate\u001b[39m\u001b[39m'\u001b[39m: pinfres,\n\u001b[0;32m   4483\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresidual as dual infeasibility certificate\u001b[39m\u001b[39m'\u001b[39m: dinfres}\n\u001b[1;32m-> 4485\u001b[0m \u001b[39mreturn\u001b[39;00m coneqp(P, q, G, h, \u001b[39mNone\u001b[39;49;00m, A,  b, initvals, kktsolver \u001b[39m=\u001b[39;49m kktsolver, options \u001b[39m=\u001b[39;49m options)\n",
      "File \u001b[1;32md:\\APP\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\coneprog.py:2256\u001b[0m, in \u001b[0;36mconeqp\u001b[1;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m misc\u001b[39m.\u001b[39mssqr(lmbdasq, lmbda, dims)\n\u001b[0;32m   2247\u001b[0m \u001b[39m# f3(x, y, z) solves\u001b[39;00m\n\u001b[0;32m   2248\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   2249\u001b[0m \u001b[39m#    [ P   A'  G'    ] [ ux        ]   [ bx ]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2253\u001b[0m \u001b[39m# On entry, x, y, z containg bx, by, bz.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[39m# On exit, they contain ux, uy, uz.\u001b[39;00m\n\u001b[1;32m-> 2256\u001b[0m \u001b[39mtry\u001b[39;00m: f3 \u001b[39m=\u001b[39m kktsolver(W)\n\u001b[0;32m   2257\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mArithmeticError\u001b[39;00m:\n\u001b[0;32m   2258\u001b[0m     \u001b[39mif\u001b[39;00m iters \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\APP\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\coneprog.py:1981\u001b[0m, in \u001b[0;36mconeqp.<locals>.kktsolver\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkktsolver\u001b[39m(W):\n\u001b[1;32m-> 1981\u001b[0m     \u001b[39mreturn\u001b[39;00m factor(W, P)\n",
      "File \u001b[1;32md:\\APP\\envs\\FSVM-CIL\\lib\\site-packages\\cvxopt\\misc.py:1460\u001b[0m, in \u001b[0;36mkkt_chol2.<locals>.factor\u001b[1;34m(W, H, Df)\u001b[0m\n\u001b[0;32m   1457\u001b[0m     base\u001b[39m.\u001b[39msyrk(A, F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m], trans \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mT\u001b[39m\u001b[39m'\u001b[39m, beta \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m, partial \u001b[39m=\u001b[39m \n\u001b[0;32m   1458\u001b[0m         \u001b[39mTrue\u001b[39;00m) \n\u001b[0;32m   1459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mis\u001b[39;00m matrix: \n\u001b[1;32m-> 1460\u001b[0m     lapack\u001b[39m.\u001b[39;49mpotrf(F[\u001b[39m'\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m]) \n\u001b[0;32m   1461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1462\u001b[0m     cholmod\u001b[39m.\u001b[39mnumeric(F[\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m], F[\u001b[39m'\u001b[39m\u001b[39mSf\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################################## Both the membership function & AFW-CIL proposed without Change rate for Yeast dataset ##############################\n",
    "C = 100\n",
    "T = 5 # Số vòng lặp\n",
    "N = 1 # Số lần bốc\n",
    "n_neighbor = 6\n",
    "\n",
    "# data = [Co_Author, Abanole, Ecoli, Ecloli1, Ecoli3, Glass1, Glass4, Haberman, Waveform, New_thyroid2, Page_blocks,\n",
    "#             Pima_Indians_Diabetes, Satimage, Transfusion, Yeast]\n",
    "\n",
    "#Haberman dataset\n",
    "# dataset = Haberman_KFold\n",
    "# beta_center, beta_estimate, beta_actual = 1, 1, 0.6 # !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!!\n",
    "\n",
    "#Ecoli dataset\n",
    "dataset = Ecoli_Kfold\n",
    "beta_center, beta_estimate, beta_actual = 0.3, 0.6, 0.7\n",
    "\n",
    "# dataset = Pima\n",
    "# beta_center, beta_estimate, beta_actual = 0.5, 1, 0.5\n",
    "\n",
    "# dataset = Transfution_Kfold\n",
    "# beta_center, beta_estimate, beta_actual = 0.5, 0.8, 0.1\n",
    "\n",
    "# dataset = Yeast_KFold\n",
    "# beta_center, beta_estimate, beta_actual = 0.9, 0.2, 0.3\n",
    "\n",
    "# from Processing_Data import Co_Author_50_250_ir, Co_Author_200_1000_ir, Co_Author_100_500_ir, Co_Author_50_250, Co_Author_250_750, Co_Author_100_900, Co_Author_100_700, Co_Author_100_500, Co_Author_50_350, Co_Author_200_1000, Co_Author_200_1000_1, Co_Author_300_1500\n",
    "# dataset = Co_Author_100_500_ir\n",
    "# beta_center, beta_estimate, beta_actual = 0.5, 0.8, 0.1\n",
    "\n",
    "name_method =[\"own_class_center\",\"estimated_hyper_lin\",\"actual_hyper_lin\",\"distance_center_own_opposite_tam\"]\n",
    "name_function = [\"lin_center_own\",\"exp\",\"func_own_opp_new\", \"func_own_opp_new_v1\",\"func_own_opp_new_v2\"]\n",
    "\n",
    "time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "filename = (str(dataset).split(\"\\\\\")[-1]).split(\".\")[0]\n",
    "filepath = f'./Experiment/Data_{filename}_Full.csv'\n",
    "\n",
    "#svc lib\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "#svm scratch\n",
    "svm_scr = Svm(C)\n",
    "#W.svm\n",
    "for n in range(0,N):\n",
    "    print(\"Lan boc: \",n+1)\n",
    "    X, y = dataset.load_data()\n",
    "    print(X.shape)\n",
    "    kfold_validation = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    header = ['Time','Fold','T','Name Method', 'Name Function', 'SP', 'SE', 'Gmean', 'F1 Score','Accuracy','AUC','Ma tran nham lan']\n",
    "    data = []\n",
    "    with open(f'./Experiment/Data_{filename}_{time}_Full.csv', 'a', encoding='UTF8', newline='') as f3:\n",
    "        writer = csv.writer(f3)\n",
    "        writer.writerow(header)\n",
    "        fold = 1\n",
    "        for train_index, test_index in kfold_validation.split(X,y):   \n",
    "            print(\"\\nFold thu \",fold)            \n",
    "            # X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "            # X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "            print(X_test.shape)\n",
    "            \n",
    "            #Scalling Data\n",
    "            sc_X = StandardScaler()\n",
    "            X_train = sc_X.fit_transform(X_train)\n",
    "            X_test = sc_X.transform(X_test)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            #################################### NOT USING AFW-CIL #####################################\n",
    "\n",
    "            #Svm library\n",
    "            print(\"SVM LIBRARY starting...\\n\")\n",
    "            test_pred = svm_lib(X_train, y_train,X_test)\n",
    "            sp,se,gmean = Gmean(y_test,test_pred)\n",
    "            name1 = 'SVM'\n",
    "            name2 = 'SVM'\n",
    "            data.append([n+1,fold,1,name1,name2,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "            \n",
    "            #Wsvm\n",
    "            print(\"W.SVM starting...\\n\")\n",
    "            N, d = X_train.shape\n",
    "            distribution_weight = np.ones(N)\n",
    "            test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "            sp,se,gmean = Gmean(y_test,test_pred)\n",
    "            name1 = 'WSVM'\n",
    "            name2 = 'WSVM'\n",
    "            data.append([n+1,fold,1,name1,name2,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "\n",
    "            # #FuzyyWsvm\n",
    "            # for namemethod in name_method:\n",
    "            #     for namefunction in name_function:\n",
    "            #         if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "            #             continue\n",
    "            #         elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v1\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v2\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "            #             continue\n",
    "            #         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "            #             continue\n",
    "            #         else:\n",
    "            #             print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "            #             distribution_weight = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "            #             __ = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "            #             test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "            #             sp,se,gmean = Gmean(y_test,test_pred)\n",
    "            #             data.append([n+1,fold,1,namemethod,namefunction,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "            \n",
    "\n",
    "            ########################################## USING AFW-CIL #############################################\n",
    "            print(\"\\n------------- Using AFW-CIL---------------------\\n\")\n",
    "            arr_tlp = is_tomek_new(X_train, y_train, class_type = [-1.0])\n",
    "            #FuzyyWsvm\n",
    "            for namemethod in name_method:\n",
    "                for namefunction in name_function:\n",
    "                    if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "                        continue\n",
    "                    elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "                        continue\n",
    "                    elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "                        continue\n",
    "                    elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                        continue\n",
    "                    elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "                        continue\n",
    "                    elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v1\":\n",
    "                        continue\n",
    "                    elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "                        continue\n",
    "                    elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "                        continue\n",
    "                    elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v2\":\n",
    "                        continue\n",
    "                    elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "                        continue\n",
    "                    elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        \n",
    "                        print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "                        distribution_weight = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "                        __ = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)                            \n",
    "                        for i in range(0,T):\n",
    "                            # new_W = lfb(f,C,distribution_weight,namemethod,namefunction,T,X_test,y_test,X_train,y_train,n_neighbor,thamso1,thamso2)\n",
    "                            new_W = data_tomelinks_final(C,distribution_weight,X_test,y_test,X_train,y_train,n_neighbor,arr_tlp,clf=None,namemethod=namemethod,namefunction=namefunction)\n",
    "                            test_pred = wsvm(C,X_train, y_train, X_test, new_W)\n",
    "                            sp,se,gmean = Gmean(y_test,test_pred)\n",
    "                            data.append([n+1,fold,i+1,namemethod,namefunction,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "                            print(\"At T = \", i+1)\n",
    "            \n",
    "            fold = fold + 1\n",
    "        writer.writerows(data)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lan boc:  1\n",
      "\n",
      "Fold thu  1\n",
      "\n",
      "Fold thu  1\n",
      "\n",
      "Fold thu  1\n",
      "\n",
      "Fold thu  1\n",
      "\n",
      "Fold thu  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C = 100\n",
    "T = 5 # Số vòng lặp\n",
    "N = 1 # Số lần bốc\n",
    "n_neighbor = 6\n",
    "\n",
    "# data = [Co_Author, Abanole, Ecoli, Ecloli1, Ecoli3, Glass1, Glass4, Haberman, Waveform, New_thyroid2, Page_blocks,\n",
    "#             Pima_Indians_Diabetes, Satimage, Transfusion, Yeast]\n",
    "\n",
    "#Haberman dataset\n",
    "# dataset = Haberman_KFold\n",
    "# beta_center, beta_estimate, beta_actual = 1, 1, 0.6 # !!!!!!! Beta with Dataset, change Data please change Beta !!!!!!!!\n",
    "\n",
    "#Ecoli dataset\n",
    "dataset = Ecoli_Kfold\n",
    "beta_center, beta_estimate, beta_actual = 0.3, 0.6, 0.7\n",
    "time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "filename = (str(dataset).split(\"\\\\\")[-1]).split(\".\")[0]\n",
    "for n in range(0,N):\n",
    "    print(\"Lan boc: \",n+1)\n",
    "\n",
    "    kfold_validation = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    header = ['Time','Fold','T','Name Method']\n",
    "    data = []\n",
    "    with open(f'./Experiment/Data_{filename}_{time}_Full.csv', 'a', encoding='UTF8', newline='') as f3:\n",
    "        writer = csv.writer(f3)\n",
    "        writer.writerow(header)\n",
    "        fold = 1\n",
    "        for train_index, test_index in kfold_validation.split(X,y):   \n",
    "            print(\"\\nFold thu \",fold)            \n",
    "            \n",
    "            name1 = 'SVM'\n",
    "            name2 = 'SVM'\n",
    "            data.append([n+1,fold,1,name1])\n",
    "            \n",
    "\n",
    "            writer.writerows(data)    \n",
    "            # fold = fold + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ######################################## Both the membership function & AFW-CIL proposed + Change rate for Waveform, Satimage dataset################################\n",
    "# C = 100\n",
    "# T = 5\n",
    "# N = 5\n",
    "# n_neighbor = 5\n",
    "# # new_rate = [1/5, 1/7, 1/9, 1/11, 1/15] #for Waveform dataset\n",
    "# new_rate = [1/11, 1/15] #for Satimage dataset\n",
    "\n",
    "# # # Waveform dataset\n",
    "# # dataset = Waveform_KFold\n",
    "# # beta_center, beta_estimate, beta_actual = 0.3, 0.2, 0.5\n",
    "\n",
    "# # Satimage dataset\n",
    "# dataset = Satimage\n",
    "# beta_center, beta_estimate, beta_actual = 0.9, 0.8, 0.2\n",
    "\n",
    "\n",
    "# name_method =[\"own_class_center\",\"estimated_hyper_lin\",\"actual_hyper_lin\",\"distance_center_own_opposite_tam\"]\n",
    "# name_function = [\"lin_center_own\",\"exp\",\"func_own_opp_new\", \"func_own_opp_new_v1\",\"func_own_opp_new_v2\"]\n",
    "\n",
    "# time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "# filename = (str(dataset).split(\"\\\\\")[-1]).split(\".\")[0]\n",
    "# filepath = f'./Experiment/Data_{filename}_Full.csv'\n",
    "\n",
    "# #svc lib\n",
    "# svc = SVC(probability=True, kernel='linear')\n",
    "# #svm scratch\n",
    "# svm_scr = Svm(C)\n",
    "# #W.svm\n",
    "# for n in range(0,N):\n",
    "#     print(\"Lan boc: \",n+1)\n",
    "#     for ir in new_rate:\n",
    "#         X, y = dataset.load_data(ir)\n",
    "#         print(X.shape)\n",
    "#         kfold_validation = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "#         header = ['Times','IR','Fold','T','Name Method', 'Name Function', 'SP', 'SE', 'Gmean', 'F1 Score','Accuracy','AUC','Ma tran nham lan']\n",
    "#         data = []\n",
    "#         with open(f'./Experiment/Data_{filename}_{time}_Full.csv', 'a', encoding='UTF8', newline='') as f3:\n",
    "#             writer = csv.writer(f3)\n",
    "#             writer.writerow(header)\n",
    "#             fold = 1\n",
    "#             for train_index, test_index in kfold_validation.split(X,y):               \n",
    "#                 # X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "#                 # X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "#                 X_train, y_train = X[train_index], y[train_index]\n",
    "#                 X_test, y_test = X[test_index], y[test_index]\n",
    "#                 print(X_test.shape)\n",
    "                \n",
    "#                 #Scalling Data\n",
    "#                 sc_X = StandardScaler()\n",
    "#                 X_train = sc_X.fit_transform(X_train)\n",
    "#                 X_test = sc_X.transform(X_test)\n",
    "#                 y_train = np.array(y_train)\n",
    "\n",
    "#                 #################################### NOT USING AFW-CIL #####################################\n",
    "\n",
    "#                 #Svm library\n",
    "#                 print(\"SVM LIBRARY starting...\\n\")\n",
    "#                 test_pred = svm_lib(X_train, y_train,X_test)\n",
    "#                 sp,se,gmean = Gmean(y_test,test_pred)\n",
    "#                 name1 = 'SVM'\n",
    "#                 name2 = 'SVM'\n",
    "#                 data.append([n+1,ir,fold,1,name1,name2,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "                \n",
    "#                 #Wsvm\n",
    "#                 print(\"W.SVM starting...\\n\")\n",
    "#                 N, d = X_train.shape\n",
    "#                 distribution_weight = np.ones(N)\n",
    "#                 test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "#                 sp,se,gmean = Gmean(y_test,test_pred)\n",
    "#                 name1 = 'WSVM'\n",
    "#                 name2 = 'WSVM'\n",
    "#                 data.append([n+1,ir,fold,1,name1,name2,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "\n",
    "#                 #FuzyyWsvm\n",
    "#                 for namemethod in name_method:\n",
    "#                     for namefunction in name_function:\n",
    "#                         if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "#                             continue\n",
    "#                         elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v1\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v2\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "#                             continue\n",
    "#                         else:\n",
    "#                             print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "#                             distribution_weight = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "#                             __ = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "#                             test_pred = wsvm(C,X_train, y_train, X_test, distribution_weight)\n",
    "#                             sp,se,gmean = Gmean(y_test,test_pred)\n",
    "#                             data.append([n+1,ir,fold,1,namemethod,namefunction,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "                \n",
    "\n",
    "#                 ########################################## USING AFW-CIL #############################################\n",
    "#                 print(\"\\n------------- Using AFW-CIL---------------------\\n\")\n",
    "#                 arr_tlp = is_tomek_new(X_train, y_train, class_type = [-1.0])\n",
    "#                 #FuzyyWsvm\n",
    "#                 for namemethod in name_method:\n",
    "#                     for namefunction in name_function:\n",
    "#                         if namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"lin_center_own\":\n",
    "#                             continue\n",
    "#                         elif namemethod ==\"distance_center_own_opposite_tam\" and namefunction ==\"exp\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v1\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v1\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"own_class_center\" and namefunction == \"func_own_opp_new_v2\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"estimated_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "#                             continue\n",
    "#                         elif namemethod == \"actual_hyper_lin\" and namefunction == \"func_own_opp_new_v2\":\n",
    "#                             continue\n",
    "#                         else:\n",
    "#                             print(f\"Fuzzy W.SVM name_method = '{namemethod}',name_function = '{namefunction}' starting...\\n\")\n",
    "#                             distribution_weight = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)\n",
    "#                             __ = fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction)                            \n",
    "#                             for i in range(0,T):\n",
    "#                                 # new_W = lfb(f,C,distribution_weight,namemethod,namefunction,T,X_test,y_test,X_train,y_train,n_neighbor,thamso1,thamso2)\n",
    "#                                 new_W = data_tomelinks_final(C,distribution_weight,X_test,y_test,X_train,y_train,n_neighbor,arr_tlp,clf=None,namemethod=namemethod,namefunction=namefunction)\n",
    "#                                 test_pred = wsvm(C,X_train, y_train, X_test, new_W)\n",
    "#                                 sp,se,gmean = Gmean(y_test,test_pred)\n",
    "#                                 data.append([n+1,ir,fold,i+1,namemethod,namefunction,sp,se,gmean,f1_score(y_test, test_pred),accuracy_score(y_test,test_pred),roc_auc_score(y_test, test_pred),str(confusion_matrix(y_test, test_pred))])\n",
    "#                 fold = fold + 1\n",
    "#             writer.writerows(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('FSVM-CIL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd073cf77417f2eda899b4964833636dfa63b2ff098a61069509a2b01c748e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
